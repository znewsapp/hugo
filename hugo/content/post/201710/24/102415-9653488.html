+++
date = "2017-10-24T15:00:00"
title = "爲什麼 AI 都打敗李世石、柯潔了，還是沒法幫我洗褲衩、做飯？"
titleimage = "https://pic1.zhimg.com/v2-035ee11f84858c12173d1004d49b5d88.jpg"
ga = 102415
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title"></h2>

<div class="answer">



<div class="content">
<p>之所以有這個疑問，是因爲<strong>我們人類和機器人對 “容易” 的定義有所不同</strong>。</p>
<p>五年前，深度學習還沒火起來的時候，經常可以看到大家用一個例子：計算機算精確定義的問題很快，如大數相乘、開根號等，但是對最簡單的物體識別則無能爲力，如認出貓。人類則正好相反。</p>
<p>目前，雖然深度學習已經很好地解決了物體識別的問題，但並不是說它已經能夠在所有問題上超越人類了，<strong>依舊還有很多跟原來識別貓一樣看起來簡單的問題</strong>。</p>
<p>其中，機器人操作物體便是其中一個情況。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-4325b35c133db1b3ea571071cd0afd2c_b.jpg" alt="">
<p>要操作一個物體，簡單地想一下，首先我們就要知道機械手的動作對物體施加了哪些作用力，然後才能判斷物體會怎麼動。</p>
<p>這中間存在一個很麻煩的東西，那就是摩擦力。摩擦力這個東西，說實話大家還不是非常瞭解它的形成機制，所以也不太可能知道它的精確模型。摩擦力估計不準，自然就沒法判斷機械人的動作會讓物體怎麼動了。</p>
<p>除了摩擦力以外，如果被操作的物體不是剛體，而是一個會變形的物體（如毛巾、衣服等），那就更不可能做了。</p>
<p>既然，傳統基於模型的方法似乎到了一定瓶頸，那麼，<strong>是否有可能用機器學習的方法來做呢</strong>？ 這個就非常有趣了。已經有一些了，<a href="https://www.zhihu.com/question/40333794">有沒有將深度學習融入機器人領域的嘗試？有哪些難點？</a>，但是遠沒有到人類的水平。</p>
<p>我們要知道，機器學習只是在做一個高維曲面擬合，所以，至少需要考慮幾個點：</p>
<ul><li><strong>提供的數據是否包含足夠的信息？</strong></li>
<li><strong>機器學習是否能夠從提供的數據裏提取到這些特徵？</strong></li>
<li><strong>機器學習算法是否有足夠強大的擬合能力？</strong></li>
<li><strong>數據量是否夠？</strong></li>
</ul><p>對於第一個問題：<strong>提供的數據是否包含足夠的信息？</strong>如果我們提供的數據有信息丟失，那肯定是無法學習出來的。</p>
<p>例如，我們想做一個分類器判斷我買的外賣好不好吃，提供訓練數據的只是各種菜的圖片和相應的好吃等級。這樣，機器學習是無法學習出來的。因爲只從圖片是無法得到食物好不好吃的所有信息。</p>
<p>對於機器人而言，也是一樣。我們有時候不知道該提供哪些數據給機器人作爲訓練，就抓取而言，是否要提供物體的質量、形狀、彈性模量等？不清楚背後的原理就沒法做判斷。胡亂訓練就只會變成一場鬧劇：<a href="https://zhuanlan.zhihu.com/p/26778071">【僞科學爭議】谷歌研究員兩萬字批駁上交大用深度學習推斷犯罪分子</a></p>
<p>與之相對應的，物體識別、或者圍棋就不一樣了，只要提供了整幅圖片、整個棋盤，就包含了完成這個任務的所有信息。</p>
<p>對於第二個問題：<strong>機器學習是否能夠從提供的數據裏提取到這些特徵？</strong>有時候，即使我們給了足夠的數據，但是機器學習也沒法從中抽取出需要的特徵。這樣，也自然無法做進行學習。</p>
<p>例如，都是做物體識別，都提供了完整的圖片。傳統的物體識別算法（如 BoW 等），只是利用了人工設計的局部特徵點的信息，無法提取到一些更有用的特徵，因此識別能力遲遲無法提高。而隨着 GPU 的發展，卷積網絡的能力被大幅挖掘出來，於是，在短短几年內，深度學習就把物體分類問題給基本解決了。</p>
<p>對於控制而言，很多問題都可以被抽象成一個馬爾科夫決策過程（MDP，Markov Decision Process）。從這個角度上看，就是說能不能從給的信息中獲取當前機器人所處的「狀態」。例如，做一個電機的角度控制，我們需要知道電機的當前狀態，然後用反饋控制。這個「狀態」可以通過編碼器直接測量，當然也可以通過一個高幀率攝像頭拍攝得到。（<strong>這個其實就是系統可觀性的概念了</strong>）</p>
<p>問題是，CNN 雖然能很好地提取圖像的特徵了，但是在機器人裏，什麼網絡才能提取到所需的特徵呢？直接給每個關節角度、力矩就行嗎？這方面還沒有一個比較好的嘗試。</p>
<p>對於第三個問題：<strong>機器學習算法是否有足夠強大的擬合能力？</strong>現在數據都有了，問題就變成了機器學習是否能夠擬合出需要的高維曲面。</p>
<p>說實話，圍棋並不是一個很簡單的任務，它的狀態維度非常高，基本不可能遍歷，機器學習要做的是如何在極其有限的數據中擬合出合適的策略，這就使得很多「顯然」的方法變得不可用（<strong>量變導致質變</strong>），AlphaGo 絕不只是計算效率高的結果。</p>
<p>在強化學習（RL，Reinforcement Learning）中，就是通過迭代的方法獲得一個高維的表格，這個表格對應着所有的狀態 s，每個狀態對應着相應的動作 a。然後，深度網絡就是用一個高維曲面來擬合這個表格。</p>
<p>至少從目前的一些應用（物體識別、AlphaGo 等）上看，深度學習的擬合能力已經足夠強了。而且，目前也有很多方法來防止過擬合 <a href="https://www.zhihu.com/question/59201590/answer/167392763?group_id=905789919117512704">fly qq：機器學習中用來防止過擬合的方法有哪些？</a></p>
<p>對於第四個問題：<strong>數據量是否夠？</strong>這個肯定是個問題。</p>
<p>對於圖像而言，可以有 ImageNet 等。但是對於機器人，就不太好採集數據了，如果讓機器人在現實生活中採集數據，那麼一方面時間太長，另一方面可能損壞機器人。如果讓機器人在仿真環境中採集數據，如何彌補仿真與實際之間的差距，又是另一個大問題了。</p>
<p>當然，或許有人會提 AlphaGo Zero 這次沒有用人類數據。但是，這並不是說它不用大量數據。只是因爲圍棋這個規則比較確定，輸贏也是明確定義的，我們就能通過給定一定規則，仿真出這些數據。</p>
<p>機器人這塊確實還是任重道遠，當然也不排除有從機器學習的角度彎道超車可能性。但要記清，<strong>機器學習也要遵守基本法</strong>，控制理論裏的可觀性、可控性還是有必要分析的。</p>
</div>
</div>

<div class="answer">



<div class="content">
<p><strong>因爲這些工作所需要的智能程度遠遠高於自動駕駛，更是遠遠遠遠高於圍棋。</strong></p>
<p>圍棋的困難之處在於盤面的可能性極多，不可能像五子棋、象棋一樣使用較爲簡單的搜索算法來解決問題（即使投入全宇宙的資源做計算機）。</p>
<p>但是相比之下，圍棋又是一個極爲簡單的問題：規則明確，所需的信息完全由 19*19 個棋盤交叉點決定，沒有任何不確定性。而且 AI 與物理環境的交互完全爲 0。</p>
<p>自動駕駛比圍棋困難得多：首先信息不完全，車輛只能通過各種傳感器收集信息，而不能簡單讀入 361 個數字；不確定性也出現了，不但各種傳感器都有誤差和侷限性，甚至規則（交規和常識）本身都有很多模糊的地方。而且無論準備多少億英里的訓練數據，都可能出現完全沒見過的特殊情況（圍棋的局面不會“完全特殊”）。車輛也處於物理環境，而不是虛擬的棋盤。</p>
<p>即便如此，相比之下，自動駕駛也是一個相對簡單的問題：車輛本身不與物理環境進行任何直接的接觸，所要做的就是避開接觸（碰撞）。車輛對於環境的感知一般分米級精度就夠了，最多也就是釐米級，並且物體（如人、車）精準的姿態和輪廓對於決策通常是不重要的。</p>
<p><strong>而使用機器人給你做菜、煮飯、洗衣服等等，就集合了前面提到的所有困難，是當之無愧的史詩級大 boss 挑戰。</strong></p>
<p>首先信息不完全，需要用傳感器感知，而且對感知精度和細緻程度的要求遠遠高於自動駕駛。對於自動駕駛，你只要知道前方大概 3.5 米有個車就行，但是機器人需要將一個土豆定位到毫米級，並且精準識別出輪廓（甚至三維形狀）才能正確操作，甚至有可能需要觸覺。如何感知衣服、線纜這樣非剛體的柔軟物體的形態，對於機器人界還是極端困難的問題。</p>
<p>家務機器人與環境的交互也比自動駕駛複雜很多：不僅僅要避開碰撞，還要與環境進行物理互動，達到預期的效果。</p>
<p>想象一下你把衣服用衣架掛起來這個動作吧！在這個任務裏，你的視覺、觸覺精密配合，雙臂、雙手靈巧地將團在一起的衣服展開，將衣服掛上去。這一切對於人類現有技術還過於複雜。</p>
<p>總之，從信息完全程度、不確定性大小、感知環境所需的精度和細緻程度、與環境交互的程度等多個維度看 ，讓機器人做家務都是遠遠遠遠難於圍棋和自動駕駛的問題。而且我還沒有提到路徑規劃、柔順控制、輕型機器臂、靈巧手等機械、控制領域的大坑，也沒有提到如何理解人的意圖甚至情緒等問題。</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-1163c136d6b5ce680b7aab859ca01bf3_b.jpg" alt="">
<p>以人類現有科技的水平，達到如 3 歲人類水平的抓取、操作物體都還有茫茫多的工作要做。作爲機器人（手臂那種）一線從業者和多年的研究者，每每看到題主這樣的問題，想到人民的期待和我輩技術水平差距之大，真是令人汗顏，慚愧不已。</p>
<p>任重道遠，且行且珍惜。</p>
</div>
</div>




</div>


</div>
</div><script type="“text/javascript”">window.daily=true</script>