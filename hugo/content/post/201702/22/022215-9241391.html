+++
date = "2017-02-22T15:00:00"
title = "社交網絡都在做個性化推薦，這是我在 Facebook 的經驗"
titleimage = "http://pic4.zhimg.com/6c961e9d92597a669b77690d76169463.jpg"
ga = 022215
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title">個性化推薦網站怎麼評價推薦質量的優劣？</h2>

<div class="answer">



<div class="content">
<p>在 Facebook 工作時負責新鮮事(Newsfeed)的個性化推薦與排序，我可以說說 Facebook 是怎麼衡量自己推薦和排序的質量的。</p>
<p>在具體執行層面，主要有三個方式，分別是從<strong>機器學習模型</strong>，<strong>產品數據</strong>，和<strong>用戶調查</strong>上來考覈推薦引擎的效果。</p>
<p><strong>1. 機器學習模型</strong></p>
<p>推薦引擎的一大核心就是機器學習（不過現在都說人工智能了，但本質上還是 supervised learning）。如果是想考察機器學習模型的質量，學術上早就有一套成熟的實踐方法。無論是模型的選擇（比如從 decision tree 替換成 neural network），還是迭代改進（比如模型訓練時多用一倍的數據），都可以使用基於 supervised learning 的衡量辦法。最常見的就是 AUC。</p>
<p>另一方面，對於某一類特定問題也有更細緻的指標。比如說，可以通過模型特徵的重要性(feature importance)知道新加的特徵是不是有用。</p>
<p><strong>2. 產品數據</strong></p>
<p>再牛逼的機器學習模型都要經歷產品數據的實際檢驗。這方面大家就都比較熟悉了，KPI 嘛。不過在 Facebook 特別是 Newsfeed 這種牽一髮動全身的地方，我們會追蹤<strong>一系列數據來描述產品，</strong>而不是依賴某一個單一標準。這些數據包括但不限於：</p>
<ul>
<li>日 / 月活躍用戶（DAU，MAU）</li>
<li>用戶互動 （點贊，評論，轉發等）</li>
<li>用戶發帖量</li>
<li>用戶停留時間和消耗的內容量</li>
<li>收入</li>
<li>用戶互動率（比如看過的內容中點贊 / 評論 / 長閱讀 / 收藏的比例）</li>
<li>用戶舉報和屏蔽的數量</li>
</ul>
<p>而且，在日常的快速迭代和 A/B 測試中，只有這些籠統的數據是不夠的，我們還需要些更細緻的數據來真正理解我們的一些改動。比如說：</p>
<ul>
<li>內容類型的分佈是怎麼變動的：用戶原創和轉發的比重分佈，網頁鏈接和圖片視頻的比重分佈，長視頻和短視頻的比重分佈等等</li>
<li>對公衆帳號是怎麼影響的：什麼樣的公衆號會受益於這次改動</li>
<li>哪些第三方巨頭受到了影響，影響是否合理：比如我最早在 FB 實習時候的項目是整頓 SPAM 帳號，那個改動重創了 Zynga（因爲 Zynga 嚴重依賴用戶騷擾他的好友來吸量），但大家覺得挺合理的，讓公關去溝通了下就發佈了。</li>
</ul>
<p>另外，爲了防止短暫的眼球效應，對每一個重要的產品決策，<strong>我們都會維護一個長期的 backtest</strong>，用來評估這個決策的長久影響。比如說：</p>
<ul>
<li>對於在 feed 裏面放廣告這個決定，我們會選擇一小部分用戶，對他們長期不顯示廣告，然後將他們的用戶活躍度同正常能看到廣告的用戶做對比，來衡量廣告的長期影響。</li>
<li>類似的，對於 Newsfeed 是否排序，我們也有一個 holdout group，他們的 feed 是完全按時間排的。</li>
</ul>
<p>這樣，對每一個可能會有爭議的決策，但未來的每個時間點，我們都能清楚的知道，我們是面臨着怎樣的取捨。有了這層保障，在決策的當下，我們也就敢於冒險些，走得更快些。</p>
<p><strong>3. 用戶調查</strong></p>
<p>大多數產品數據有其侷限性，因爲他們是<strong>顯性而被動</strong>的。比如說，你給用戶推送了一個博眼球的低俗內容，用戶在當下可能是會去點開看的，所以數據上是好的。但用戶可能心裏對這個內容的評價是低的，連帶着對作爲內容平臺的產品也會看輕，長此以往對產品的傷害是巨大的。</p>
<p>KPI 無法完全描述產品質量，在硅谷互聯網圈是有共識的，但如何解決，每個公司答案都不同。Twitter 系的 CEO 們，無論是 Jack Dorsey 還是 Evan Williams，都傾向於輕視 KPI 而依賴自己主觀想法來決策。Google 和 Facebook，則採取了另一條路，<strong>他們決定把用戶評價納入到 KPI 中</strong>。</p>
<p>Google 在這方面的工作開始得比較早，因此公開的資料也比較多。概括地說，他們僱傭大量的普通人，以用戶的角度來對 Google 搜索排序的質量和廣告推薦的質量做主觀打分。當打分的量大到一定程度，這些數據就足以成爲一個穩定有效的，且可持續追蹤並改進的 KPI 了。Facebook 雖然產品領域有所不同，但在個性化推薦上也採取了類似的方法。</p>
<p>回答的最後，還是想重申兩個方法論：</p>
<ul>
<li><strong>永遠不能依靠單一一個 KPI 來評價產品上的工作。</strong>任何 KPI，任何產品，都不能。</li>
<li>在明確 KPI 侷限性的前提下，<strong>數字可以終結大多數無意義的扯皮</strong>，無論是技術上的，還是政治上的。</li>
</ul>
</div>
</div>




</div>


</div>
</div>