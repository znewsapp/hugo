+++
date = "2017-02-28T15:00:00"
title = "我們離電影《終結者》中的人形機器人還有多遠？"
titleimage = "http://pic4.zhimg.com/9bfee2171e89af64018322a91697f76b.jpg"
ga = 022815
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title"></h2>

<div class="answer">



<div class="content">
<p>由於我個人的研究方向主要集中在機械臂這塊，機器人的其他領域只知皮毛，所以這邊也只能結合自己的經驗，粗略說一說。</p>
<p>先說結論，《美國機器人路線圖 2016 版》中指出：『在未來 10-15 年內，我們基本不可能製造出全能的通用機器人』，而我個人也比較認同這一觀點。所以，我就猜一個大於 15 的數字，<strong>大概還需要 50 年</strong>。</p>
<p>《終結者》系列電影是我最喜歡的科幻電影之一，第一部《終結者》電影還是小學時跟我媽一起看的。但是，即使是 1984 年的 T-800 機器人也已經遠遠強於目前世界上的真實機器人。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-b64c22380f7fe943d6f024d7b1828570_b.jpg" alt="">
<p>要想做出類似 T-800 性能的機器人，我認爲我們現在還有很多路要走。相對於其他技術（ 智能手機、VR 眼鏡、移動支付等），機器人涵蓋的技術領域更廣。所以，下面我根據機器人的研究領域，分別大概談談現在機器人的研究進展與問題。</p>
<p>（<strong>以下非本人熟悉領域的內容均爲道聽途說，如有誤，歡迎在評論區指出</strong>）</p>
<p>其中，T-800 機器人的信息基本上來自一個叫做『<strong>終結者百科』</strong>的網站<a href="http://terminator.wikia.com/wiki/T-800">T-800</a>，（現在真是什麼網站都有了&hellip;&hellip;）</p>
<ul>
<li><strong>硬件、機構</strong>：</li>
</ul>
<p>我們先看看 T-800 吧</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-e06fa9b49c8e1df97a18b9862e6eb9b7_b.jpg" alt="">
<p>可以看出，T-800 的機構設計基本<strong>模仿人體</strong>進行自由度分配，骨架爲超合金（也稱<strong>高溫合金</strong>），另外，驅動器採用的是<strong>液壓模塊</strong>；此外， 能源是小型<strong>核反應堆核燃料電池</strong>（可以連續工作 120 年）。當然，施瓦辛格飾演的 T-800 具有<strong>人的外貌</strong>。</p>
<p>感謝機械前輩們幾百年的積累，目前在硬件方面，實際機器人已經不會比 T-800 差了，甚至可能優於 T-800。下面是幾個比較著名的真實機器人：</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-c4a11aa539c805267e379c44085550e9_b.jpg" alt="">
<p>但是，在<strong>能源方面</strong>，我們離 T-800 還有一段距離。現在的移動機器人基本上都需要攜帶一個巨大的電池，續航能力也不行。這方面只能寄希望於新一代電池技術的發明了。</p>
<p>除此之外，T-800 在一些細節方面也超過了現在的機器人研究水平：無摩擦軸承、能承受手榴彈攻擊的高強度骨骼、包含人體內循環在內的活體組織等。當然，這幾個不是人形機器人的必備功能。</p>
<ul>
<li><strong>感知：</strong></li>
</ul>
<p>這個包括兩個部分，一個是傳感器，一個是信號處理：</p>
<p><strong>傳感器</strong>：機器人需要能夠感知周圍環境和自身狀態，因此需要安裝不同的傳感器。當然，這裏我們不清楚 T-800 到底安裝了哪些傳感器，所以簡單猜一下：聽覺傳感器（可以聽到聲音）；多光譜高分辨率相機（能夠夜視、放大等）；力矩傳感器；皮膚觸覺傳感器（可以感受到別人觸碰到自己）。</p>
<p>首先是聽覺傳感器，這個似乎沒有什麼特殊的，普通麥克風即可。</p>
<p>其次，是相機，現在機器人的視覺傳感器應該比 T-800 豐富，高精度相機、紅外相機、深度相機、激光雷達等等。沒辦法，算法不夠，傳感器來湊嘛。</p>
<p>之後，是力矩傳感器，主要用於檢測關節力矩。有了精確的關節力矩纔有可能部署一些控制算法、估計環境狀態。當然，現在這樣的傳感器也已經有了，但就是貴。</p>
<p>最後，也是唯一與 T-800 有差距的地方，是皮膚觸覺傳感器：這個基本上還有很多路要走，不信的話看看下圖吧，這是去年 RA-Letter 上發表的一篇論文的工作： A Conformable Force/Tactile Skin for Physical Human-Robot Interaction</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-8f75547e5917845326d1abd29b9405b0_b.jpg" alt="">
<p><strong>信號處理算法</strong>：當然，這裏的信號處理是廣義的信號處理，包括普通的濾波、傅里葉變換等，也包括物體識別、語音識別等人工智能算法。這個話題就太大了，而且我們與 T-800 差距也非常大，我簡單列幾個：</p>
<p>物體識別 / 語音識別：當然，隨着近幾年深度學習的發展，我們在物體識別和語音處理方面的造詣已經非常厲害了，從前段時間百度的機器人『小度』在《最強大腦》中的表現可見一斑。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-c0df5a3791180b1507e9dec0e5742800_b.jpg" alt="">
<p>語義理解：前面的語音識別是指根據聲音識別出文字，這裏則是理解識別的文字內容。T-800 與人類接近的水平就不說了，而我們現在研究的最高水平，可以參考<a href="http://www.msxiaoice.com/">微軟小冰</a>聊天機器人，基本還是比較笨的。PS：不要跟我說什麼機器人『嬌嬌』，那是後面有個人在遙控。</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-481a11af2e9d3810c21a2a30c409ae11_b.jpg" alt="">
<p>環境理解 / 地圖創建：這個簡單地說，就是機器人對環境建模的能力，包括地圖創建等。T-800 就不說了，已經可以全球到處跑，甚至穿越時空回到從沒見過的過去也沒問題。相反的，現在的機器人在這一塊還是比較弱的，即使配備了激光傳感器等額外的設備（T-800 只有雙目相機），也只能在一些特定條件下完成地圖創建，而基於地圖的環境理解也只能算剛起步不久，如下面這個語義地圖。</p>
<img class="content-image" src="http://pic3.zhimg.com/70/v2-7b91f9c057908d1b0f311266978921d2_b.jpg" alt="">
<p>當然，我覺得之後隨着深度學習技術在地圖創建等領域的應用，（考慮到深度學習對環境理解的能力），這個領域估計有可能在十年內出現可實用的技術。</p>
<ul>
<li><strong>規劃</strong>：</li>
</ul>
<p>規劃是指根據任務和機器人當前狀態，計算出完成這個任務的方法。包括且不限於：任務規劃（將大任務劃分爲幾個小的子任務），運動規劃（機械臂或者足式機器人各關節運動軌跡），路徑規劃（其實跟運動規劃類似，不過傾向於爲移動機器人規劃形式路徑）。T-800 的規劃水平已經跟人差不多，所以就不提了，來看看我們現在的機器人吧：</p>
<p>任務規劃：舉個例子，我們想讓機器人送瓶雪碧，那麼機器人會將這個大任務分解成幾個子任務（運動到冰箱前 --&gt;打開冰箱 --&gt;找到雪碧 --&gt;拿出雪碧 --&gt;關上冰箱 --&gt;送到人面前），當然，可以有更復雜的任務。目前，一般是採用 MDP 或 POMDP 模型來描述問題，然後用各種規劃算法求解。總體上說，現在的任務規劃強烈依賴於任務描述方式（人工指定），而且在應對大規模、不完全可觀等複雜問題時，還沒有可靠的方法。</p>
<p>運動規劃：舉個例子，機器人面前有一杯水，讓機器人將手運動到杯子面前，同時不能碰到桌子等障礙物。這就是運動規劃，根據目標狀態點，生成一系列關節運動狀態。是的，<strong>現在就連讓機器人拿起面前的杯子這樣的問題也還沒有完全解決</strong>。簡而言之，我們一般是採用基於隨機採樣的算法進行運動規劃的。隨機採樣的意思就是：每次規劃的結果可能不同，更無法保證規劃出的路徑是最優的。因爲自己就做這一塊，所以深知其中的坑。就我個人感覺，要解決運動規劃問題，需要一個方法論上的創新，拋棄現在這套方法（因爲人肯定不是這樣規劃的啊）。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-0d6712556f6c9c8be038760349e4bfdc_b.jpg" alt="">
<p>路徑規劃：其實跟運動規劃是一個問題，但由於路徑規劃一般是在地面上，問題維度低，可以採用一些奇奇怪怪的規劃方法（Dijkstra，A* 等）。由於問題畢竟簡單，這塊的發展也比較好，例如各種掃地機器人就已經可以在室內環境中到處跑了。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-9fbe920f8bbe379ff82a909e64274bbc_b.jpg" alt="">
<p>當然，這一塊需要解決的問題可能是：①動態環境；②擁擠環境；③複雜地形；④地圖不全的環境等。但是估計未來 15 年左右可以徹底解決，所以到那時候，估計無人駕駛車已經可以到處跑了。</p>
<p><strong>控制</strong>：</p>
<p>控制就是具體執行規劃結果的過程了，從底層的電機控制到上層的機器人全身控制都屬於這個範疇。我不清楚 T-800 的控制是怎麼做的，但看他可以到處跑、跳，基本可以確定現在的機器人控制技術還沒達到這個水平。但我們可以簡單看看現在的機器人控制已經什麼水平了：</p>
<p>機械臂控制：下圖是大約十年前 Sami Haddadin 做的機械臂碰撞檢測的 demo，基本上已經非常厲害了。而且，由於機械臂控制屬於機器人自身動力學問題，所以目前看來，這一領域可以說已經是完全攻克了。</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-8c3dba0cdd799ca7c8994b4d9491fb53_b.jpg" alt="">
<p>機械手操作：但是，機械手的抓取操作問題就沒這麼簡單了，因爲其中涉及實際物理環境的建模問題（摩擦力、形狀等），由於模型不精確，所以完全基於模型的方法很難解決這一問題。目前實際應用基本還是採用平行夾持器的方式。只有不少研究機構在進行靈巧手抓取方面的研究。</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-3ada9d77d554f7fe3d9c96100dc1e359_b.jpg" alt="">
<p>足式機器人控制：這是更難的地方了，因爲機械臂和機械手都至少有個相對固定的基座。足式機器人的 base 是會隨着接觸而發生變化的。所以，我一直覺得能做足式機器人控制的人都是很厲害的人。雖然很難，但還是有一些逆天的公司做出了不錯的足式機器人》。</p>
<img class="content-image" src="http://pic3.zhimg.com/70/v2-fe51dafd33afc02d57f691cb75e0e46e_b.jpg" alt="">
<p>上面這幾個足式機器人真的已經超級厲害了，但是它們跟 T-800 比起來，依舊還是渣渣。</p>
<ul>
<li><strong>學習</strong>：</li>
</ul>
<p>這個屬於另外一大塊內容，由於可以應用到其他領域（控制、規劃、感知等），所以有時候不能單獨列爲一類。衆所周知，現在深度學習很厲害了，但依舊需要依賴大量標記數據。</p>
<p>我之前在另一個回答（<a href="https://www.zhihu.com/question/55286082/answer/144223182">小扎說人工智能仍需要人類給出足夠的引導，機器人需要完成&ldquo;無人指導下的學習&rdquo;，目前這種理論目前是否存在？ - fly qq 的回答 - 知乎</a>）中提到過，機器學習分爲監督學習、無監督學習和強化學習三類。目前，深度學習主要在監督學習方面得到了很好的應用；此外，對於強化學習，也逐漸以 Deep Q Learning 等形式出現；但無監督學習纔是機器學習中的最高挑戰。</p>
<p>T-800 在電影中能學習微笑等奇怪的技能（也可以直接從數據庫中下載知識學習），正得益於其超強的學習能力。而其能根據數據庫中的人體解剖信息，習得如何高效殺死人類（根據『終結者百科』），說明其已經具有了較強的無監督學習能力。</p>
<img class="content-image" src="http://pic3.zhimg.com/70/v2-638f40d4a02369a6b28997ef1fd7afae_b.jpg" alt="">
<p>當然，機器學習的坑還有很多。因爲，正是不斷學習讓我們能夠面對不斷變化的環境。這方面可挖的東西太多了。</p>
<ul>
<li><strong>交互</strong>：</li>
</ul>
<p>這個就是機器人與人交互的問題。包括識別人、與人交流、與人協作。在這個角度看，T-800 已經跟常人無異（甚至強於人類）。但是，我們現在的機器人則還不盡如人意：</p>
<p>識別人：雖然人體識別在機器視覺中已經有了很多成果，但是在人機交互過程中，機器人不僅要識別到人的存在，還應該要能判斷人的動作、意圖，並作出相應反饋。</p>
<p>與人交流：這方面，T-800 早已經通過『圖靈測試』了（可以混入人類軍隊）；而我們的聊天機器人雖然也已經做得不錯了，但離通過『圖靈測試』還很遠，隨便一個普通人都能輕易判斷出對面是一個機器人。</p>
<p>與人協作：這個就不說了，T-800 不僅可以與人一起做簡單的協同工作，還能夠給人分配工作。。。。；而我們真實的機器人還只能這樣：</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-6e73e6652d329b8852d7ed9797d2013d_b.jpg" alt="">
<p><strong>容錯性</strong>：</p>
<p>這個就是說機器人的軟硬件發生故障後，依舊可以自適應地完成部分工作，我們比 T-800 還是差很多：</p>
<p>T-800 是這樣的：融解得只剩手了，還能給你點贊。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-7c92dd113780a15a443d6a4f7b63469c_b.jpg" alt="">
<p>我們的機器人最強只能這樣：</p>
<p>2014 年發表在 Nature 的成果，只是簡單的機構損壞、核心部件完好。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-5b0cdf6558d3080a188aa89c700a95c0_b.jpg" alt="">
<p><strong>綜上，要想做到跟《終結者》中的 T-800 那樣的通用機器人，我們還有非常非常非常遠的路要走，前面說的 50 年都已經是很樂觀的估計了</strong>。</p>
<p>當然，要想在十年內做出這樣的機器人也不是不可能，例如忽然來了一羣奇怪的人說要教我們機器人技術：</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-cbd00d40e8c2692f0ac223a76d15c39b_b.jpg" alt="">
</div>
</div>




</div>


</div>
</div>