+++
date = "2017-06-08T20:00:00"
title = "聰明的 Siri 又升級了，蘋果正式加入人工智能服務競爭"
titleimage = "https://pic4.zhimg.com/v2-10d377ac5eb03e4af8959a55e4770987.jpg"
ga = 060820
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title"></h2>

<div class="answer">

<div class="content">
<p>回答來自機構帳號：<a href="https://www.zhihu.com/org/shao-shu-pai-46">少數派</a></p>
</div>
</div>


</div>





<div class="question">
<h2 class="question-title">蘋果在 WWDC 2017 上發佈了哪些有關 Siri 的更新？如何看待 Siri 之後的發展？</h2>

<div class="answer">



<div class="content">
<p>AI（人工智能）競賽正在不斷升級，它已經不僅僅停留在原來的用戶數據層面，也不再只滿足於軟件服務的層面。隨着去年 Amazon Echo 的大熱以及 Google Home 的推出，AI 的競爭已經來到了硬件層面上。雖然蘋果的高管曾表態不看好 Amazon Echo 這樣的產品，然而，今年 <a href="https://www.apple.com/homepod/">HomePod</a> 的推出，表明蘋果正式加入了人工智能服務的競爭。</p>
<p>鑑於 HomePod 的正式面世要到年底，我們只能暫且擱下硬件層面不談，從數據、軟件服務的層面，來看看蘋果的人工智能。</p>
<p><strong><strong>口音更自然的 Siri，也有更多新能力</strong></strong></p>
<p>Siri 正在變得不處不在。2016 年的 WWDC，蘋果花了<a href="https://sspai.com/post/35537">大篇幅來介紹 SiriKit</a>，向部分領域的第三方開發者開放了能力，使得音視頻通話、健身、消息服務、支付、搜索照片和視頻、叫車類的 app 可以直接通過用戶與 Siri 語音交互的形式，理解用戶的需求，並提供服務。</p>
<p>今年，蘋果沒有停下腳步，SiriKit 的開放領域再一次升級。除了原有的幾個領域外，SiriKit 還新增了下列開放能力：</p>
<ul>
<li><strong>清單：</strong>除了系統自帶的備忘錄，其它第三方清單或任務管理類的 app 也可以接入 SiriKit，實現用 Siri 創建任務與提醒事項、查看清單等；</li>
<li><strong>二維碼：</strong>你可以直接讓 Siri 顯示你的二維碼，Siri 就可以將你的二維碼直接展示到屏幕上，方便朋友掃描，添加你爲好友；</li>
<li><strong>支付：</strong>通過與 Siri 語音對話，來向你的朋友轉賬；</li>
<li><strong>連接 CarPlay：</strong>通過與 CarPlay 聯動，Siri 可以直接控制車內的溫度，並切換電臺；</li>
</ul>
<p>除了 SiriKit 開放能力的升級，Siri 現在說話的口音，也更加自然了，蘋果爲 Siri 創建了更自然的語音合成方式。不過從 WWDC 現場演示的情況來看，這個口音自然感的提升，目前似乎只針對英語，中文的改善程度並不顯著。</p>
<p>除了 SiriKit 之外，Siri 本身也有了兩項新能力：翻譯以及音樂相關的能力。</p>
<p>你只需要對 Siri 說「How do you say what are the most popular dishes in your restaurant in Chinese」，Siri 就會<strong>顯示相應的中文翻譯結果，並支持一鍵朗讀</strong>。目前，Siri 僅支持將英語翻譯爲中文、西班牙語、法語、德語、意大利語等五國語言，之後會不斷加入新語言的支持。</p>
<p>除了翻譯之外，Siri 和 Apple Music 也有了更好的聯動。當你對 Siri 說「放點歌」的時候，它會自動尋找 Apple Music 中你喜愛的音樂，或根據你的歷史記錄，向你推薦可能喜歡的歌曲。另外，爲了與 HomePod 這個家庭音樂中心相配合，Siri 現在也可以根據歌曲的詳情信息，做出一些複雜的回答，比如你可以直接問 Siri「這首歌的編曲是誰」、「這首歌是什麼時候發行的」、「Justin Bieber 的最新專輯是什麼」，Siri 也會告訴你答案。</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-de90b2bcf2c2989bea9b970bf52f8b47_b.jpg" alt="">
<p>蘋果在 watchOS 4 中也全面集成了 Siri，使它成爲了你的全天候助理。在新加入的 Siri 錶盤中，Siri 會主動提供你接下來需要關注的事情，例如日程、待辦事項、航班信息、交通信息等。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-79fda0a9c1d2ee6a1887d1106d7a354c_b.jpg" alt="">
<p><strong>三個系統層面的智能聯動</strong></p>
<p>從去年開始，蘋果就強調 Siri 不僅僅是一個有形的語音助手，它還是遍佈系統各處的無形的智能引擎。它不再像 Google Now 或者 Google Assistant 一樣，只有在你主動長按 Home 鍵時纔出現，Siri 和人工智能已經遍佈在系統各處，例如相冊的人臉識別，文字輸入的情景預測，Spotlight 搜索時的 Siri 建議。</p>
<p>蘋果眼中的人工智能，顯然不僅僅只是一個具體化的產品形態，而是遍佈各處、互通互聯的一種能力，讓你在不經意間，發現這個系統真的懂你。去年 iOS 10 推出時，我們就在<a href="https://sspai.com/post/35537">文章中</a>介紹了大量這樣的特性。例如，iOS 10 中的<a href="https://sspai.com/post/35386">地圖應用</a>，你只需要複製一個地址，打開地圖應用，它就會智能地提示你是否要搜索這個地址。</p>
<p>在 iOS 11 中，蘋果繼續拓展着這個思路，一個顯而易見的例子，就是在設置中，將 Siri 設置與曾經深藏在「通用 - Spotlight 搜索」的設置，合併在了一級入口「Siri &amp; Search」，原先 Spotlight 建議中的搜索建議和查詢建議，直接成爲了新的 Siri 建議。</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-d4d831a5009c848a54e64ec9fc9b5435_b.jpg" alt="">
<p>除此之外，延續着互通互聯的思路，iOS 11 還新增了三個系統層面的智能聯動：</p>
<ul>
<li><strong>Safari：根據你當前正在瀏覽的內容，Safari 會提供智能搜索建議。</strong>同時，如果你剛剛在網頁了訂了飛機票，或確認了日程，也會觸發智能提醒，建議你添加相關的日程；</li>
<li><strong>QuickType：每次在輸入文字的時候，iOS 11 會根據你過去一段時間內的瀏覽記錄，找到相應的電影名稱、地名等，方便你直接輸入。</strong>在 WWDC 上演示了一個場景，你剛剛正在 Apple News 中瀏覽完冰島相應的旅遊地點，這時候切換到 iMessage 和好友聊天時，你只需要輸入「Re」，QuickType 就會智能地提供輸入建議「Reykjavik（冰島的首都）」。</li>
<li>Apple News：根據你的瀏覽記錄，iOS 11 會學習你感興趣的話題，並向你推薦相關的內容，不過，國內的用戶依然無法使用 Apple News。</li>
</ul>
<img class="content-image" src="http://pic3.zhimg.com/70/v2-ed845410b4c9a2ede33d9d62073c0916_b.jpg" alt="">
<p><strong><strong>iOS 11 爲開發者帶來的 Core ML</strong></strong></p>
<p>在看完了面向消費者的變化，作爲 WWDC，既然本身是面向開發者的，那不妨來簡單瞭解一下，對於開發者而言，除了 SiriKit 的升級之外，蘋果今年的重頭戲之一，還有一個 Core ML。</p>
<p>讓我儘可能用簡單，且儘可能正確的語言來說明一下這件事情的意義。</p>
<p>科普：傳統程序的白盒與機器學習的黑盒</p>
<p>在說 Core ML 之前，我們不妨來簡單說一下到底什麼是機器學習。</p>
<p>一段程序是有目標的，我們輸入一個前提條件（入參），經過程序的設定（處理機），輸出一個結果（出參）。然而，隨着我們想解決的問題不同，不同的目標會影響程序是如何被設定的，正是在如何設定程序的這一步，將傳統程序與機器學習區分開來。</p>
<p>例如，我們希望創建一個簡單的計算正方形周長的程序，你只需要輸入邊長 a 這個前提條件，計算機很容易就可以輸出周長是 4a。在這個處理機中，程序員清清楚楚地告訴計算機，對於任何輸入的 a，你只需要把它乘上 4，就完成任務了。這時候處理機實際是一個「透明的」白盒，任何人都能輕易理解實現的細節。</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-09889e60918e77dbe12afec6c517d36d_b.jpg" alt="">
<p>然而，讓我們換一個小目標：識別一張照片上有沒有小貓。這個程序的輸入非常明確，就是一張照片，同樣，我們所希望輸出的目標也非常明確，就是最後給出一個結果，要不是有貓，要不是沒有。但是，這時候一名程序員，該如何編碼程序的設定？或者說，你要寫一段怎麼樣的程序，能讓計算機明白什麼是小貓？</p>
<p>這時候就需要機器學習發揮用途了。我們通過大量已經存在的數據，不斷地標記出哪些照片上是有貓的，哪些照片是沒有貓的，把這些數據大量地「喂」給計算機，通過一些算法，從中不斷地提取其中的特徵值，計算機最終會擬合出一個模型。這個模型，人類可能完全不明白裏面的參數是如何挑選而又設定的，但這不重要，這時候的處理機，是一個黑盒，我們不關心中間發生了什麼，只要我們訓練出一個得當的模型，之後再讓它判斷未知的情況，它能夠在很大概率上給出正確的結果，這個模型就成功了。</p>
<img class="content-image" src="http://pic3.zhimg.com/70/v2-84282f71e0ba425237929bca458688ea_b.jpg" alt="">
<p><strong>Core ML 如何幫助程序員更容易地讓自己的 app 具備人工智能</strong></p>
<p>你可能發現了，要實現機器學習，其實是分了兩個階段的，第一個階段是訓練並得到模型，第二個階段則是在得到模型後，實際應用它。Core ML 解決的，其實只是後一個環節，儘管相比起模型的訓練，第二個階段，即模型應用的門檻要低不少，但它依然是意義重大的。</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-951e1e9d1f21b991d17c833c3df135a1_b.jpg" alt="">
<p>在 Core ML 存在之前，如果你想在自己開發的 app 上使用機器學習，你不僅僅需要自己訓練出一套模型，還需要將得到的模型與你的 app 連通起來，這個過程有點像，你僅僅只是想過一座河，卻需要先自己搭一座橋。</p>
<p>現在，有了 Core ML，你可以將自己訓練得到的模型，藉助蘋果提供的轉換工具，先轉化成 Core ML 類型的模型文件，然後，Core ML 這座橋已經搭好了，你可以通過它，直接實現模型和 app 數據的互通。你的 app，可以直接把一張照片，通過 Core ML 爲基礎的 API，傳遞到機器學習的模型當中，然後模型來判斷這張照片裏有沒有小貓，並將得到的結果告知你。</p>
<img class="content-image" src="http://pic2.zhimg.com/70/v2-3d7e71d55595d936ca13b785dfb5356d_b.jpg" alt="">
<p>更深入細節一些，可以看看蘋果官方文檔中的結構圖。這四層結構中，Core ML 層原先是不存在的，也就是我們前面說的，以前開發者想要使用一套訓練好的模型，不得不自己搭這座橋樑。</p>
<p>最底層的 Accelerate 和 Metal，其實是蘋果去年推出的接口，前者可以直接調用 CPU，後者則直接調用 GPU。由於是相當底層的接口，可以最大程度地利用硬件資源來處理模型數據，蘋果也在發佈會上聲稱，其人臉識別能力，比 Google Pixel 上快六倍。</p>
<p>而 Core ML 往上一層則是應用層。Vision 主要負責圖像相關的人工智能處理，如人臉識別、面部追蹤、文字識別等等。這裏面的很多接口，在原先的 iOS 中就已經存在，這次則被統一整合到了新框架當中。好處在於，開發者擁有了更大的自由度。在以前，開發者的 app 調用這些高級接口，對底層的實現細節的掌控力度非常小，幾乎沒有。現在，你可以通過自定義底層所使用的機器學習模型，從而實現更個性化的需求。</p>
<p>說回人話，可以舉個例子。在以前，開發者只能調用蘋果的接口，識別一張照片中是否有人臉存在。但是，如果我只想識別有沒有男人的臉存在，或者，有沒有黑人的臉存在，這時候怎麼辦？因爲底層的人臉識別模型，是蘋果定死的，你沒有任何定製化的空間。現在，你完全可以在底層讓 Core ML 調用一套你獨家祕製的黑人臉識別模型，從而讓上層的 Vision API 實現更個性化的功能。</p>
<p>目前，Core ML 支持各類主流的神經網絡模型，包含深度神經網絡、遞歸神經網絡、卷積神經網絡、向量機、線性模型等等。聽着很厲害對不對，對。好的，我們開始下一個話題。</p>
<p><strong>一條蘋果特色的機器學習之路</strong></p>
<p>在 Sundar Pichai 的帶領下，Google 的戰略已經徹底從 Mobile First 轉型成爲 AI First，從今年的 Google I/O 就可見一斑，整場發佈會下來，幾乎所有的產品線與更新，都是圍繞 AI 展開的。</p>
<p>蘋果這兩年下來，也動作不少。不過相比起 Google 整天把 AI 掛在嘴邊，蘋果倒是喜歡用更務實的字眼 ML（機器學習）。從去年的 <a href="https://mp.weixin.qq.com/s?src=3&amp;timestamp=1496762873&amp;ver=1&amp;signature=76AQ9bwcRQEv0*UyNRoJkVxvM2T23MbRAufNKT-aIXKPk8laPtXz8ZisAmPnEEG0jeN34X92xclBdyDwoTcnvRueLSZVLTvXwhtCoLvBwE2itSDdSe-MFdNSb7vi63Vv9SV0xggw36soCffrbB2GiTme8BugmwW7k9QALwJsA4k=">Differential Privacy</a> 到今年的 Core ML，蘋果已經走出了一條具有蘋果特色的機器學習之路。</p>
<p>重視隱私的蘋果，在機器學習領域面對的兩大難題</p>
<p>這一切都源於蘋果對隱私的重視。作爲一家消費品公司，蘋果的主要使命是賣硬件，而不像 Google 本質上是一個需要收集大量數據的廣告公司。這給了蘋果更多的底氣，儘可能地不去觸碰用戶的數據，而在很長一段時間內，這樣的策略，引發了兩個非常實際的問題。</p>
<p>我們前面說到了，機器學習可以簡單分爲訓練模型和應用模型兩個階段。而蘋果的隱私策略，也相應地使之在這兩個階段面臨兩大難題。</p>
<p>第一個難題，是在模型訓練階段，在儘可能不收集用戶數據的前提下，如何優化模型？既使像蘋果在去年的 WWDC 上宣稱的「我們不需要收集所有用戶拍的照片，才知道山長什麼樣子」，也依然不能迴避的事實是，在模型的調優方面，少不了大量的數據支撐。想從 95% 的水平提升到 99% 的水平，數據還是不可缺少的一環。</p>
<p>第二個難題，是在模型應用階段，如何做到儘可能在設備本地完成處理？早期受限於設備的性能和功耗，特別是移動設備的電量問題，許多公司選擇將數據上傳至雲端後，由雲端服務器來進行運算，只將結果返回給終端設備。</p>
<p>總結下來，<strong>蘋果的目標，就是在儘可能不收集用戶數據的基礎上，也能調校出足夠好用的模型，同時儘可能只在消費者的設備本地運用模型進行計算處理。</strong></p>
<p>隱私與人工智能，可以兼得</p>
<p>目前來看，蘋果離這個目標越來越近了。</p>
<p>在相對簡單的模型應用方面，蘋果已經實現了高度的本地化計算。iOS 10 和 11 當中的一系列智能特性，例如相冊中的人臉識別，都完全是在 iPhone 等設備本地完成的，這次的 Core ML，也給了第三方開發者以能力，在不上傳用戶資料的前提下，僅在設備本地就可以應用機器學習的模型。這一切，自然和移動設備的 CPU 與 GPU 計算能力的快速增長密不可分，在能耗可控的前提下，這些原本只能在服務器端的計算，已經可以在手機上就能完成。而另一方面，得益於蘋果對軟硬件的全面掌控，也使得蘋果可以在更底層上，用 Accelerate 和 Mental 更全面地利用 CPU 和 GPU 的性能。</p>
<p>這次 Core ML 的推出，使得蘋果從系統級到第三方開發者，都具備了僅在設備本地就可以進行模型處理的能力。那麼下一個尚待解決的問題，就是模型的訓練。前文提到的 Differential Privacy，使蘋果已經可以做到抽樣性地，以匿名的方式從用戶手中回收一部分數據，這些數據可以不斷改進訓練蘋果的模型，同時又確保無法從中定位到任何一個具體的用戶。</p>
<p>目前，這樣的能力尚沒有開放給第三方開發者，但有理由相信，蘋果最終將補齊這一塊短板，使得開發者也可以通過一定的類似 Differential Privacy 的機制，在絕對保證用戶隱私的基礎上，獲取能夠改進機器學習模型的數據，以更好地訓練並調優模型。</p>
<p>就像我曾說的，在隱私和人工智能面前，蘋果認爲魚與熊掌是可以兼得的。這種「貪心」，大概就是蘋果特色的機器學習之路。</p>
<hr>
<p>原文發表於少數派：<a href="https://sspai.com/post/39551">既要讓 Siri 更聰明，還要保護你的隱私，這是蘋果「貪心」的機器學習之路</a></p>
<p>作者：<a href="https://sspai.com/user/648292">子不語 Rex</a></p>
</div>
</div>




</div>





<div class="question">
<h2 class="question-title"></h2>

<div class="answer">

<div class="content">
<p>「知乎機構帳號」是機構用戶專用的知乎帳號，與知乎社區內原有的個人帳號獨立並行，其使用者爲有正規資質的組織機構，包括但不限於科研院所、公益組織、政府機關、媒體、企業等。這不僅是知乎對機構的「身份認證」，更是涵蓋了內容流通機制、帳號規範等全套帳號體系。和個人帳號一樣，機構帳號開通不需要任何費用，同時也受社區規範的監督管理，並要遵守相關協議。目前機構帳號入駐採用邀請制。您可以通過<span class="s1">&nbsp;&nbsp;<a href="http://zhihu.com/org-intro"><span class="s2">什麼是「知乎機構帳號」</span></a>&nbsp;</span>來了解更多機構帳號信息。</p>
</div>
</div>


</div>


</div>
</div>