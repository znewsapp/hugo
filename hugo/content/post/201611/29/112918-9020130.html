+++
date = "2016-11-29T18:00:00"
title = "AI 脣讀術完虐行業專家，只看了 5000 小時的節目"
titleimage = "http://pic1.zhimg.com/6e95388e55f16a44829f2b26f79cd274.jpg"
ga = 112918
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">



<div class="question">
<h2 class="question-title"></h2>
<div class="answer">



<div class="content">
<p>編者注：人工智能搶人類飯碗的趨勢越來越明顯了，最近，它又瞄準了一個新行業，而且一出手就比該行業專家們做的好。</p>
<p>主角還是 AI 大咖谷歌 DeepMind，這次他們與英國牛津大學合作，通過機器學習大量的 BBC 節目，來學習一項全新的技能：脣讀術。可怕的是，人工智能不僅學會了，而且讓脣讀專家們自愧不如。</p>
<p>脣讀是人類一項獨特的技藝，也是非常困難的一件事，它對於語言語境和知識理解的要求並不亞於視覺上的線索，然而 AI 又做到了。</p>
<img class="content-image" src="https://pic4.zhimg.com/v2-050664e20404655a83c9aab7650009f7_b.jpg" alt="">
<p>AI 系統的學習對象是近 5000 小時的 BBC 各類節目，包括 Newsnight、BBC Breakfast、Question Time 等，所有視頻資料加起來約有 11.8 萬句話。</p>
<p>谷歌 DeepMind 和牛津大學的聯合研究團隊使用了 2010 年 1 月至 2015 年 12 月間的電視節目素材對 AI 系統進行訓練，然後使用 2016 年 3 月 - 9 月間播出的節目進行 AI 性能測試。</p>
<img class="content-image" src="https://pic4.zhimg.com/v2-21811025559531e1c0fc35871d63bac3_b.jpg" alt="">
<p>BBC 節目數據庫。從左至右分別爲：頻道、節目名稱、小時數、句數</p>
<p>通過觀察節目中說話者的脣形，AI 系統可以準確解讀出文字，比如下面這些比較&ldquo;拗口&rdquo;的句子：&ldquo;我們知道也將有上百位記者會出席&rdquo;（We know there will be hundreds of journalists here as well），以及&ldquo;根據國家統計局的最新統計數據&rdquo;（According to thelatest figures from the Office of National Statistics）。</p>
<p>DT 君試讀了以上英文語句，發現脣形變化其實並不明顯，而且電視節目中的語速是非常快的，<strong>難度可想而知。</strong></p>
<img class="content-image" src="https://pic1.zhimg.com/v2-52d0729c970fe67ed83b14c53f61de2c_b.jpg" alt="">
<p>BBC 節目數據庫中無字幕原片</p>
<img class="content-image" src="https://pic2.zhimg.com/v2-d515bb9912a486e8042692c4d5c8b4ad_b.jpg" alt="">
<p>由谷歌 DeepMind AI 系統通過脣讀同步的字幕</p>
<p><strong>AI 能力再升級</strong></p>
<p>測試結果的具體數據可能更能說明問題：在 2016 年 3 月 -9 月的節目庫中隨機選取的 200 個說話場景脣讀對比測試中，<strong>人類專家的完全準確率爲 12.4%，而 AI 的完全準確率爲 46.8%</strong>。</p>
<p>而且 AI 所犯錯誤中有很多其實無關緊要，比如在複數後面漏掉一個&ldquo;s&rdquo;之類。不過哪怕是這樣，AI 還是完虐了人類脣讀專家。</p>
<p>人工智能業內專家稱，&ldquo;這絕對是建構全自動脣讀系統的第一步！現有的各類龐大數據庫完全可以支持深度學習技術的發展。&rdquo;</p>
<img class="content-image" src="https://pic3.zhimg.com/v2-0bb5a4e7bc608a8dddfd3ba0af1e4a22_b.jpg" alt="">
<p>上方彩色圖片爲 BBC 節目數據庫原始靜態圖片，下方黑白圖片爲兩個不同的人說出&ldquo;afternoon&rdquo;（下午）這個單詞時的脣型</p>
<p>兩週前，牛津大學曾開發了一個類似的深度學習系統 LipNet，這套系統當時就已 93.4% 對 52.3% 大比分擊敗了人類脣讀專家，但還不太說明問題，畢竟，LipNet 和人類的競賽是基於 GRID 語料庫，這個數據庫只包含<strong>51 個特殊詞彙</strong>。</p>
<p>而 DeepMind 這次選取的 BBC 節目數據庫卻包含了驚人的<strong>17500 個特殊詞彙</strong>，對人工智能來說，這無疑是艱鉅的挑戰。</p>
<img class="content-image" src="https://pic2.zhimg.com/v2-ce2b04898c4eb7b2c816c3cb02e6e635_b.jpg" alt="">
<p>GRID 語料庫中的音視頻數據相對簡單得多</p>
<p>除此之外，BBC 節目數據庫中包含了人類在正常說話時使用的各種語法，而 GRID 語料庫的 33000 個句子都採用相同表達，這使得句子很容易被預測，難度也相對低得多。</p>
<p>DeepMind 和牛津大學的研究團隊將開放 BBC 節目數據庫供同行使用。來自 LipNet 的 Yannis Assael 表示將率先使用這一數據庫來訓練自己的脣讀 AI 系統。</p>
<p><strong>把嘴脣排列起來</strong></p>
<p>如果要通過 BBC 節目這一類的視頻數據庫來訓練自動脣讀系統，必須要讓機器預先學習每一個視頻片段。可問題是，<strong>節目中的視頻流與音頻流往往不是完全同步的</strong>，甚至會出現多達 1 秒左右的時間差。</p>
<p>簡單地說，這會讓機器徹底蒙圈，因爲視頻裏出現的脣形沒辦法和音頻完美貼合，機器就<strong>無法將某一特定脣形和其發音對號入座</strong>。這樣看來，AI 學習脣讀術好像是不可能的。</p>
<img class="content-image" src="https://pic1.zhimg.com/v2-76ca6849a9da8b923820143f781ed048_b.jpg" alt="">
<p>解決這一問題的方案是讓計算機先學會那些完全同步的音視頻流，掌握髮音與脣形間的關聯，然後<strong>自行推斷音視頻流中那些畫面是不同步的，再進行自動修正</strong>。DeepMind 的 AI 系統自動處理的 5000 小時音視頻流就是採用的這種方法。如果完全使用人工來進行同步校準，工作量簡直大到不可想象。</p>
<img class="content-image" src="https://pic2.zhimg.com/v2-88b53afce7b8a7c90882c452ccd33209_b.jpg" alt="">
<p>DeepMind 採用的&ldquo;看、聽、嘗試、拼寫&rdquo;架構。首先解碼出一個特徵 yi 及兩個向量，再通過向量去定位對應的輸入音頻視頻流序列</p>
<p>好了，問題來了，AI 脣讀本事這麼大，到底會被用來幹嘛？DT 君腦子裏首先出現的畫面就是：&ldquo;天網&rdquo;默默監視着全人類的談話，<strong>只要看看嘴型就知道你在說什麼</strong>&hellip;&hellip;</p>
<p>雖然細思恐極，但專家說了，說到監聽這事兒，與其如此大動干戈，還不如超遠程監聽麥克風來得簡單直接效果好。所以，目前來看，沒什麼好害怕的。</p>
<img class="content-image" src="https://pic4.zhimg.com/v2-dd5f41dddce4f809b0c41f009fd9a44b_b.jpg" alt="">
<p>相比之下，AI 脣讀技術更可能的應用方向是<strong>消費類電子設備</strong>，可以讓設備知道用戶想要說什麼，哪怕不發出聲音。&ldquo;動動嘴皮子&rdquo;這種事兒搞不好會成爲未來人機交互的常態。</p>
<p>來自牛津大學 LipNet 研究團隊的 Yannis Assael 對此技術的評價是：&ldquo;我們相信 AI 脣讀技術是一種非常實用的輔助性技術，比如更智能的助聽器、不便出聲的公共場合（Siri 再也不用聽見你的聲音了），以及在嘈雜環境下精準的語音識別等。&rdquo;</p>



</div>
</div>
</div>


</div>
</div>