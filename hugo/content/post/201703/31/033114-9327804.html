+++
date = "2017-03-31T14:00:00"
title = "Siri：「你說了什麼？我不太明白」"
titleimage = "https://pic4.zhimg.com/v2-67f6df6e28a65d99c6fa991484d85463.jpg"
ga = 033114
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title">語音識別領域的最新進展目前是什麼樣的水準？</h2>

<div class="answer">



<div class="content">
<p>其實語音識別在發音規範且背景噪音可以得到合理控制的情況下，很多年前就已經可以勉強實用了，很多尖端系統在工程水平很高的情況下甚至可以做的更好，比如早期的 Siri，以及 DARPA 項目語音識別評測中的各種參賽系統。當時前沿研究的困難和今天差不多，一方面是複雜條件下（自然發音、口音、複雜噪聲等等）識別率顯著下降的問題；另一方面是語音的訓練和測試用數據的匹配問題（比如用朗讀人民日報的語音做的模型很難用來準確識別電話對話語音）。傳統上解決第一個問題，除了高超的工程技巧外，還會使用聲學模型自適應等方式；而第二個問題則有不同的解決思路，比如偏向研究，想要對語音本質有更深入理解的方式。</p>
<p>Chin-Hui Lee, "From knowledge-ignorant to knowledge-rich modeling: A new speech research paradigm for next-generation automatic speech recognition"</p>
<p>另外就是更計算機科學家的方式，即收集更多更多的數據來改進統計模型。代表性的工作我認爲應該是 2015 年過世的方棣棠老師和他夫人李樹青老師的論文：</p>
<p>方棣棠，李樹青，"漢語語音識別產品走向實用的途徑"</p>
<p>方老師提出要收集百萬個說話人的電話撥號或命令詞控制語音，來完成一個在實際應用中足夠魯棒的簡單語音識別器，可惜因爲學術界的條件限制，在當時的條件下很難達成。事實上，這種數據量的限制在學術界一直長期存在，學術界語音識別研究使用的所謂大數據量多年來也不過只是一兩千小時語音的規模，再不斷增加數據量，不但人力、存儲、運算等代價顯著增加，同時識別器性能提升的收益也在下降（其實這個問題今天也依然存在）。進一步說，數據量的限制對學術界的影響很普遍，比如計算機視覺研究的數據量傳統上其實比語音識別的更小，還比如 Deep Learning 剛開始興起的時候，Hinton 等幾位教授的研究組其實關注的都是小數據量的學習問題，甚至是無監督或弱監督的學習。</p>
<p>語音識別產品普遍的性能提升應該是從深度學習在（基於 HMM 的）語音識別器中應用開始的，當時領先的工作出自與 Hinton 教授合作的微軟、IBM、Google 等公司，最代表性的工作包括</p>
<p>G.E. Hinton et. al, "Deep Neural Networks for Acoustic Modeling in Speech Recognition"</p>
<p>G. Dahl et. al, "Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition"</p>
<p>F. Seide et. al, "Conversational speech transcription using context-dependent deep neural networks"</p>
<p>當時 DNN 使用在語音識別中主要的三個顯著的作用。一是可以顯著提高識別器的性能，這樣即使沒有高超的工程技巧也可以做出實用效果很好的語音識別器；而是性能提升很穩定，即使當時效果最好的識別器，在把 GMM 換成 DNN 之後也普遍有 10%左右的提升；三是方便了大數據的使用。因爲神經網絡大量使用矩陣和向量運算進行計算，並且神經網絡的結構很容易進行擴展從而可以更好的配合大數據的使用。很多傑出的高性能計算領域人才的介入直接讓語音識別等方向可以更高效率的使用規模大的多的數據（比如十萬小時語音等）。在 DNN 和大數據量的條件下，很多複雜工程技巧的作用下降了，甚至說話人自適應等方式也都不再同樣重要，這又極大的降低了語音識別產品的研發門檻，並且提高了在諸如語音輸入法、語音搜索等產品中的實用性。</p>
<p>之後語音識別的研究逐漸越來越多的受到深度學習研究的影響。DNN 之後，包括 RNN 和 TDNN 的復興，CNN、LSTM、CLDNN 等更復雜模型的應用。之所以叫做復興是因爲 RNN 最早的大規模應用就在語音識別中，而 TDNN 則根本就是在語音識別中提出的，並且啓發了 CNN 的研究，論文見：</p>
<p>A. Robinson and F. Fallside, "The utility driven dynamic error propagation network"</p>
<p>A. Waibel et. al, "Phoneme recognition using time-delay neural networks"</p>
<p>同時，神經網絡的訓練方式也在向着傳統語音識別中更常用的序列化區分性準則發展，比如</p>
<p>A. Graves and N. Jaitly, "Towards end-to-end speech recognition with recurrent neural networks"</p>
<p>D. Povey et. al. "Purely sequence-trained neural networks for ASR based on lattice-free MMI"</p>
<p>之所以沒把 CTC 列入是因爲包括 A. Graves 自己都證實了傳統語音識別中考慮所有可能候選的訓練準則效果更好，並且 CTC 在小數據等一些情況下的效果還有爭議。另外類似 CTC 的工作其實在早期語音識別研究中可以找到不少（但確實 A. Graves 的工作最完整，並且得到了 Google 的大力推動）。</p>
<p>基於以上很多技術，在某些特定的應用場景中，一定限定條件下（比如特定數據集上的電話對話語音識別），語音識別器已經初步達到或者接近人類的識別能力，見</p>
<p>G. Saon et. al, "The IBM 2016 English conversational telephone speech recognition system"</p>
<p>W. Xiong et. al. "The Microsoft 2016 conversational speech recognition system"</p>
<p>但這並不意味着語音識別器就真正完全達到 / 超過人類的識別能力。首先人類語音識別能力的魯棒性相當好，而對於機器語音識別，當更換使用場景（比如不同麥克風、背景噪聲、說話人口音、談話內容等）時，語音識別器的性能就會有顯著下降。另一方面，當機器使用海量數據（比如幾十萬、幾百萬小時語音）試圖改善魯棒性問題時，人類卻並不需要這麼多語音就可習得更好的語音識別的能力。本質上的原因仍然是我們對人類語音識別的機理缺乏足夠的認知。不過近年來有許多認知科學的相關研究都取得了一定進展，比如將深度學習與人腦關聯對認知機理進行的探索：</p>
<p>D. Yamins et. al, "Predicting IT and V4 Neural Responses With Performance-Optimized Neural Networks"</p>
<p>B. Devereux et. al, "Using neural network models of conceptual representation to understand the</p>
<p>stages of visual object processing in the ventral stream"</p>
<p>C. Wingfield et. al, "Multi-level representations in speech processing in brain and machine: evidence from EMEG and RSA"</p>
<p>需要注意的是即使在使用同樣深度學習方法時，高超的工程技巧仍然可以帶來語音識別器性能的顯著差別，這在近年來一系列的國際評測已經有足夠的體現。正像微軟公司的黃學東院士所說的：『達到人類水平的對話語音識別，與其說是算法的勝利，不如說是&lsquo;工程的奇蹟&rsquo;』。</p>
<p>另外隨着深度學習對語音識別領域影響的加深，不同於傳統 HMM 框架的語音識別器也正在發展。CTC 雖然不依賴 HMM，但基本可以基於 HMM 類似實現，並且類似的純神經網絡語音識別器也早就存在，比如前面引用的 RNN 和 TDNN 的文獻。更有意思的應該是近年來在 NLP 等方向中受到追捧的 encoder-decoder 的端到端方法。這種方法聯合學習語音和語言的所有信息，並沒有顯式的馬爾科夫性假設，從而極大的降低搜索解碼以及數據資源收集的難度。但這種方法在語音識別中還面臨很多問題。具體來說，包括模型記憶長度的問題、語音數據和語言聯合學習導致的嚴重的資源限制、應用中靈活性的限制、缺乏 lattice 生成算法等導致的對系統融合等後處理的困難等等。所以實用系統中目前最理想的還是傳統的統計語音識別框架（基於 HMM 的，或者類似的 CTC 等等）。不過這種 encoder-decoder 方法目前是非常好的研究平臺，有很多開創性的工作可以做。另外，多語言、小數據量、無監督或弱監督學習仍然是語音識別的研究長期以來的熱點和難點。</p>
<p>最後要提到的是語音識別工具包對語音識別技術和產業發展帶來的巨大推進，比如 Sphinx、HTK、Kaldi 等。基於這些工具包演化出了主流的語音技術、極大的降低了研發的門檻，使得更多人和機構可以免除長年的技術積累而通過使用和逆向分析工具包快速進入語音識別領域。</p>
</div>
</div>




</div>





<div class="question">
<h2 class="question-title"></h2>

<div class="answer">

<div class="content">
<p>更多討論，查看<span class="s1">&nbsp;</span>知乎圓桌<span class="s1">&nbsp;&middot;&nbsp;<a class="internal" href="https://www.zhihu.com/roundtable/jiqiganzhi?utm_campaign=official_account&amp;utm_source=zhihudaily&amp;utm_medium=link&amp;utm_content=roundtable">人工智能 &middot; 機器感知</a></span></p>
</div>
</div>


</div>


</div>
</div>