+++
date = "2017-05-11T17:00:00"
title = "語音識別很牛嗎？來試試《施氏食獅史》和《季姬擊雞記》"
titleimage = "https://pic2.zhimg.com/v2-5e0b53e85fefb1a0b5021cf01950da25.jpg"
ga = 051117
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title">語音識別如何處理漢字中的「同音字」現象？</h2>

<div class="answer">



<div class="content">
<p>outline：</p>
<p>1、背景</p>
<p>2、通俗易懂版</p>
<p>3、進階版</p>
<p>4、多音字的處理能力</p>
<p>&nbsp;</p>
<p><strong>1、背景</strong></p>
<p>GB 2312 標準共收錄 6763 個漢字，其中一級漢字 3755 個，二級漢字 3008 個。對於人名、古漢語等方面出現的罕用字，GB 2312 不能處理，這導致了後來 GBK 及 GB 18030 漢字字符集的出現。漢語的聲母共有 23 個，韻母 24 個。普通話的讀音共有 420 個左右，即使考慮聲調，總數也遠小於漢字的個數。</p>
<p>漢字中的同音字現象這裏也無需多費口舌來介紹，直接呈上我國著名語言學家、&ldquo;現代語言學之父&rdquo;趙元任先生的兩篇文章。</p>
<p>《施氏食獅史》</p>
<p>石室詩士施氏，嗜獅，誓食十獅。施氏時時適市視獅。十時，適十獅市。是時，適施氏適市。施氏視十獅，恃矢勢，使是十獅逝世。氏拾是十獅屍，適石室。石室溼，施氏使侍拭石室。石室拭，施氏始試食十獅屍。食時，始識十獅實十石獅屍。試釋是事。</p>
<p>《季姬擊雞記》</p>
<p>季姬寂，集雞，雞即棘雞。棘雞飢嘰，季姬及箕稷濟雞。雞既濟，躋姬笈，季姬忌，急咭雞，雞急，繼圾幾，季姬急，即籍箕擊雞，箕疾擊幾伎，伎即齏，雞嘰集幾基，季姬急極屐擊雞，雞既殛，季姬激，即記《季姬擊雞記》。</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-5a87284013b698d255a89f51bca32a6f_b.jpg" alt="">
<p>（網圖，侵刪）</p>
<p>這兩篇文章通篇都是同音字，儘管只有聲調的差異，但是想通暢的讀下來，還是需要認真練習幾遍。下面我們就來聊聊這樣的同音字文章，語音識別是否可以搞定。</p>
<p><strong>2、通俗易懂版</strong></p>
<p>語音識別處理同音字的方法，一句話來概括就是根據上下文關係。</p>
<p>下面舉例來說明這個過程。比如有一段語音，共有四個字，我們依次來看每個字的發音。</p>
<ul>
<li>a)首先我們聽到第一個音&ldquo;wǔ&rdquo;。人來判斷的話，這個字的可能性也是很多的，可以是{五、午、舞、武、吾、捂}等等等等，實在不好做出選擇。</li>
<li>b)聽到第二個音之後，語音變成&ldquo;wǔ&middot;r&eacute;n&rdquo;的時候，選擇就發生了變化。有些字開頭從來沒見過這種組合，所以就被排除了。現在組合可能是{五人、武人、舞人、五仁}等等等等。這個時候如果非要給出一個選擇，我們可能會選擇一個最常見的，比如&ldquo;五人&rdquo;。</li>
<li>c)當這段語音的第三個音出現的時候，語音變成了&ldquo;wǔ&middot;r&eacute;n&middot;yu&egrave;&rdquo;。這時候選擇又發生了變化，一些不大可能的組合被排除掉，一些可能性更大的組合被放到了前面。現在組合可能是{舞人月、無人月、無人約、武人月、伍仁月}等等。有些組合可能聲調不對卻仍然被列在了候選中，這是因爲識別的時候其它聲調也有一些可能性，不能完全排除，萬一是人發錯了音呢。</li>
<li>d) 這段語音所有的字都給出之後，語音變成&ldquo;wǔ&middot;r&eacute;n&middot;yu&egrave;&middot;b&igrave;ng&rdquo;。這時候，大多數人的第一反應大概就是&ldquo;五仁月餅&rdquo;。當然其它的可能性也不是沒有，但要比這個漢字組合的可能性小。</li>
</ul>
<p>如果用拼音輸入法，依次輸入上述拼音的時候，可以看到候選項的變化如下。當然每個人的候選是不相同的，它會根據個人的習慣改變候選排序。</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-04572b2ee0ed7ce2751ab89c3ca281ff_b.jpg" alt="">
<p>使用語音輸入法，通常給出的都是可能性最大的一個結果，所以看不到候選。但可以通過輸入的語音，觀察隨着語音長度變化，識別結果的變化。</p>
<img class="content-image" src="http://pic3.zhimg.com/70/v2-dda5b926ad4ec266ce3034773c24ac82_b.jpg" alt="">
<p><strong>3、進階版</strong></p>
<p>先祭出公式：</p>
<img class="content-image" src="http://pic4.zhimg.com/70/v2-a966e5e1d23bfa77d6300b6963caa72f_b.jpg" alt="">
<p>上式中 W 表示漢字序列，Y 表示語音輸入。公式 1 表示語音識別的目標是在給定語音輸入的情況下，找到可能性最大的漢字序列。根據 Baye&rsquo; Rule，可以得到公式 2，其中分母表示出現這條語音的概率，它同要求解的漢字序列沒有參數關係，可以在求解時忽略，進而得到公式 3。公式 3 中第一部分表示給定一個漢字序列出現這條音頻的概率，它就是語音識別中的聲學模型；第二部分表示出現這個漢字序列的概率，它就是語音識別中的語言模型。</p>
<p>聲學模型可以理解爲是對發聲的建模，因此它能夠把語音輸入轉換成聲學表示的輸出，或者簡單的理解成拼音的輸出。如果給定了唯一的拼音序列，要求解漢字序列，那麼這個問題就簡化成了同拼音輸入法類似的問題。當然聲學模型的輸出不是唯一的拼音序列，而是很多種拼音序列組成的網格（lattice），所以聲學模型的解碼要比輸入法的設計複雜。</p>
<p>拋開聲學模型，我們假定已經知道了唯一的拼音序列，現在只需求解漢字序列，問題簡化成了通俗易懂版本。下面我們來看語言模型如何在發揮作用，排除多音字的干擾。</p>
<p>關於語言模型，目前最常見的是 N-Gram 語言模型和基於 RNN 的語言模型，這裏先介紹下 N-gram 的語言模型。</p>
<p>首先考慮給定一句話：</p>
<img class="content-image" src="http://www.zhihu.com/equation?tex=s%3Dw_1w_2w_3...w_m" alt="">
<img class="content-image" src="http://www.zhihu.com/equation?tex=w_i" alt="">
<img class="content-image" src="http://www.zhihu.com/equation?tex=P%28s%29%3D%26P%28w_1%29%5Ctimes+P%28w_2%7Cw_1%29%5Ctimes+P%28w_3%7Cw_1w_2%29%5Ctimes+...+%5Ctimes+P%28w_m%7Cw_1w_2...w_%7Bm-1%7D%29%5C%5C+%26%3D%5Cprod+_%7Bi-1%7D+%5EmP%28w_i%7Cw_1...w_%7Bi-1%7D%29" alt="">
<img class="content-image" src="http://www.zhihu.com/equation?tex=w_i" alt="">
<img class="content-image" src="http://www.zhihu.com/equation?tex=L%5E%7Bi-1%7D" alt="">
<img class="content-image" src="http://www.zhihu.com/equation?tex=P%28w_m%7Cw_1...w_%7Bm-1%7D%29" alt="">
<ul>
<li>a)當 n=1 時，即出現在第 i 位上的基元 wi 獨立於歷史， n-gram 被稱爲一階馬爾柯夫鏈(uni-gram 或 monogram)</li>
<li>b)當 n=2 時, n-gram 被稱爲 2 階馬爾柯夫鏈(bi-gram)</li>
<li>c)當 n=3 時, n-gram 被稱爲 3 階馬爾柯夫鏈(tri-gram)</li>
<li>。。。。。。</li>
</ul>
<p>爲了保證條件概率在 i=1 時有意義，同時爲了保證句子內所有字符串的概率和爲 1，可以在句子首尾兩端增加兩個標誌: w1 w2 &hellip; wm 。據此，對於 n&gt;2 的 n-gram，上述整句的概率就簡化成了如下面的形式：</p>
<img class="content-image" src="http://www.zhihu.com/equation?tex=P%28s%29%3D%5Cprod_%7Bi%3D1%7D+%5E%7Bm%2B1%7DP%28w_i%7Cw_%7Bi-n%2B1%7D%5E%7Bi-1%7D%29" alt="">
<p>利用 bi-gram 來計算前面例子中&ldquo;五仁月餅&rdquo;的概率：</p>
<p>P(五仁月餅）=P(五|)&times;P(仁|五)&times;P(月|仁)&times;P(餅|月)&times;P(|餅)</p>
<p>同理，其他漢字序列的概率也可以由此公式計算得到。最終在輸入法的列表中給出概率最大的幾個選項即可。對於識別也是一樣，如果識別結果只有一個，那麼就給出概率最大的一個結果；如果識別結果是 N-best 那麼就根據概率給出可能性最大的 N 個識別結果。</p>
<p>對於 RNN 的語言模型，參數量並不會隨着句子序列長度的增加而發生變化，因此不需要馬爾柯夫鏈的前提假設。因此它是對整句進行的概率計算:</p>
<img class="content-image" src="http://www.zhihu.com/equation?tex=P%28s%29%3D%5Cprod_%7Bi%3D1%7D%5EmP%28w_i%7Cw_1...w_%7Bi-1%7D%29" alt="">
<p>其中每一次概率計算</p>
<img class="content-image" src="http://www.zhihu.com/equation?tex=p%28w_m%7Cw_1...w_%7Bi-1%7D%29" alt="">
<p>都是一次 RNN 的前向計算。</p>
<p>對於如何計算 P(仁|五)就是語言模型的構建的問題了，這裏就不再詳細介紹，感興趣的同學可以自行學習。對 N-gram 語言模型感興趣的同學，可以參考宗成慶老師的《統計自然語言處理》；對 RNN 語言模型感興趣的同學可以閱讀這篇文章[Rafal Jozefowicz, 2016]。</p>
<p><strong>4、多音字的處理能力</strong></p>
<p>最後我們回到背景介紹中的問題。現在的語音識別系統能否識別漢字中的多音字問題呢？答案是在一定程度上可以，比如正常的說話通常可以正確識別。但結果是依據統計學給出的概率上最可能的結果。</p>
<p>對於趙元任老先生的這 2 篇文章是否可以識別呢？還是直接來看訊飛手機輸入法的識別結果。普通話好的各位同學自行嘗試。</p>
<img class="content-image" src="http://pic1.zhimg.com/70/v2-5caa9155aef128d739d3870531372edc_b.jpg" alt="">
<p><strong>參考文獻：</strong></p>
<p>1、信息交換用漢字編碼字符集：</p>
<p><a href="http://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E4%BA%A4%E6%8D%A2%E7%94%A8%E6%B1%89%E5%AD%97%E7%BC%96%E7%A0%81%E5%AD%97%E7%AC%A6%E9%9B%86/8074272">http://baike.baidu.com/item/ 信息交換用漢字編碼字符集 /8074272</a></p>
<p>2、普通話音節表：</p>
<p><a href="http://humanum.arts.cuhk.edu.hk/Lexis/lexi-mf/mandarin_syllables.php">http://humanum.arts.cuhk.edu.hk/Lexis/lexi-mf/mandarin_syllables.php</a></p>
<p>3、《統計自然語言處理》宗成慶</p>
<p>4、Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, Yonghui Wu, Exploring the Limits of Language Modeling, 2016</p>
<hr>
<p>想知道更多關於語音識別、機器學習的研究成果應用，歡迎關注 Rokid 知乎機構號：<a href="https://www.zhihu.com/org/rokid-51/posts">知乎 - 知乎</a></p>
<p>未經允許，請勿轉載</p>
</div>
</div>




</div>





<div class="question">
<h2 class="question-title"></h2>

<div class="answer">

<div class="content">
<p>更多討論，查看&middot; 知乎圓桌&nbsp;<a class="internal" href="https://www.zhihu.com/roundtable/ziranyuyan">人工智能 &middot; 語言智能</a></p>
</div>
</div>


</div>


</div>
</div>