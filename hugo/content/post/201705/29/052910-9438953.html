+++
date = "2017-05-29T10:00:00"
title = "20 萬、50 萬、100 萬年薪的算法工程師，區別在哪？"
titleimage = "https://pic4.zhimg.com/v2-be0aa633d00bcaef612d257539e765d7.jpg"
ga = 052910
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">



<div class="question">
<h2 class="question-title">20 萬、50 萬、100 萬的算法工程師，到底有什麼區別？</h2>
<div class="answer">



<div class="content">
<p>公元七世紀，在車遲國國家氣象局組織的一次求雨活動中，虎力、鹿力、羊力三位大仙成功地祈下甘霖，於水火中救了黎民。老國王雖然不明就裏，卻從此尊他們爲國師，奉道教爲圭臬。</p>
<img class="content-image" src="https://pic1.zhimg.com/v2-1694e0f7958cebf6687253be1cbe5618_b.jpg" alt="">
<p>本世紀，算法工程師們的境遇也差不多：早些年，信奉糙快猛主義的大佬們覺得他們飽食終日、無所用心，沒工作只好在學校混博士，靠數據上的障眼法裝神弄鬼。可是，隨着去年 AlphaGo 大破李世石，大佬們在心底喊出&ldquo;我操&rdquo;的同時，慌不擇路地把各種搞劫持、送外賣的生意包裝成人工智能，並紛紛請來幾位懂算法的國師加持。雖然他們對國師們所做的事智商上並不理解，卻虔誠地希望他們快點兒求下雨來。</p>
<p>於是，算法工程師的身價也水漲船高了。各門派工程師不論過去練的是 java、php 還是 excel，都放棄了最好語言的爭論，抄起了深度學習，發誓重新修煉成算法工程師。前些天，還有人在知乎上問我：<strong>20 萬、50 萬、100 萬的算法工程師，到底有什麼區別？</strong></p>
<p>這樣充滿銅臭味兒的問題，讓我十分欣慰。雖說在北京，20 萬已經基本不可能招到靠譜兒的算法工程師了，還是姑且用上面的數字做個參照，談談算法工程師的三個層次吧。（這裏說的算法，並不是計算機系本科課程《算法與數據結構》裏那個算法。那門課裏講的，是排序、查找這類&ldquo;確定性算法&rdquo;；而這裏我們說的，是用統計方法對數據進行建模的&ldquo;概率性算法&rdquo;。）下文中會提到一些算法和模型，但不過是爲了舉例說明概念，無需深究，有興趣鑽研的朋友可以自己查閱資料。</p>
<p><strong>第一層次&ldquo;<strong>Operating&rdquo;：</strong>會使用工具</strong></p>
<p>這個層次的工程師，對常用的模型比較熟悉，來了數據以後，好歹能挑個合適的跑一下。</p>
<p>達到這個層次，其實門檻不高。早些年，您只要掌握了什麼叫 LDA、哪叫 SVM，再玩過幾次 libnear、mahout 等開源工具，就可以拿到數據後跑個結果出來。到了深度學習時代，這件事兒似乎就更簡單了：管它什麼問題，不都是拿神經網絡往上堆嘛！最近，經常會遇到一些工程師，成功地跑通了 Tensorflow 的 demo 後，興高采烈地歡呼：我學會深度學習了，我明天就統治人類了！</p>
<p>這事要真這麼簡單，我是茄子。任憑你十八般開源工具用的再熟，也不可能搞出個戰勝柯潔的機器人來。這裏要給大家狠狠澆上一盆冷水：進入這個領域的人，都要先了解一個&ldquo;<strong>沒有免費的午餐定理</strong>&rdquo;，這個定理的數學表達過於晦澀，我們把它翻譯成並不太準確的文藝語言：</p>
<blockquote><strong>如果有兩個模型搞一次多回合的比武，每個回合用的數據集不同，而且數據集沒什麼偏向性，那麼最後的結果，十有八九是雙方打平。</strong></blockquote>
<p>管你是普通模型、文藝模型還是 2B 模型，誰也別瞧不起誰。考慮一種極端情況：有一個參賽模型是&ldquo;隨機猜測&rdquo;，也就是無根據地胡亂給個答案，結果如何呢？對，還是打平！所以，請再也不要問&ldquo;聚類用什麼算法效果好&rdquo;這樣的傻問題了。</p>
<p><strong>這就很尷尬了！因爲掌握了一堆模型並且會跑，其實並沒有什麼卵用。</strong>當然，實際問題的數據分佈，總是有一定特點的，比方說人臉識別，圖中間怎麼說都得有個大圓餅。因此，問&ldquo;人臉識別用什麼模型好&rdquo;這樣的問題，就有意義了。而算法工程師的真正價值，就是洞察問題的數據先驗特點，把他們表達在模型中，而這個，就需要下一個層次的能力了。</p>
<p>會使用工具，在算法工程師中僅僅是入門水平，靠這兩把刷子解決問題，就好比殺過兩隻雞就想做腹腔手術一樣，不靠譜兒程度相當高。如果不是在薪酬膨脹嚴重的互聯網界，我覺得 20 萬是個比較合理的價格。</p>
<p><strong>第二層次&ldquo;<strong>Optimization&rdquo;：</strong>能改造模型</strong></p>
<p>這個層次的工程師，能夠根據具體問題的數據特點對模型進行改造，並採用相應合適的最優化算法，以追求最好的效果。</p>
<p>不論前人的模型怎麼美妙，都是基於當時觀察到的數據先驗特點設計的。比如說 LDA，就是在語料質量不高的情況下，在 PLSA 基礎上引入貝葉斯估計，以獲得更加穩健的主題。雖說用 LDA 不會大錯，但是要在你的具體問題上跑出最好的效果，根據數據特點做模型上的精準改造，是不可避免的。</p>
<p>互聯網數據這一現象更加明顯，因爲沒有哪兩家公司擁有的數據是相似的。百度的點擊率模型，有數十億的特徵，大規模的定製計算集羣，獨特的深度神經網絡結構，你能抄麼？抄過來也沒用。用教科書上的模型不變應萬變，結果只能是刻舟求劍。</p>
<p>改造模型的能力，就不是用幾個開源工具那麼簡單了，這需要有兩方面的素養：</p>
<p><strong>一、<strong>深入瞭解</strong>機器學習的原理和組件。</strong>機器學習領域，有很多看似不那麼直接有用的基礎原理和組件。比方說，正則化怎麼做？什麼時候應該選擇什麼樣的基本分佈？(如下表) 貝葉斯先驗該怎麼設？兩個概率分佈的距離怎麼算？當你看到前輩高人把這些材料烹調在一起，變成 LDA、CNN 這些成品菜餚端上來的時候，也要想想如果自己下廚，是否瞭解食材，會不會選擇和搭配。僅僅會吃幾個菜，說出什麼味道，離好廚師差的還遠着呢。</p>
<img class="content-image" src="https://pic2.zhimg.com/v2-2e6654cb4bd3f7d8d8b344b8da088f59_b.jpg" alt="">
<p><strong>二、熟練掌握最優化方法。</strong>機器學習從業者不懂最優化，相當於武術家只會耍套路。這就跟雷公太極和閆芳大師一樣，實戰起來一定是鼻青臉腫。管你設計了一個多牛逼的模型，如果無法在有限的計算資源下找出最優解，那麼不過是個花瓶罷了。</p>
<p><strong>最優化，是機器學習最、最、最重要的基礎。</strong>你要知道，在目標函數及其導數的各種情形下，應該如何選擇優化方法；各種方法的時間空間複雜度、收斂性如何；還要知道怎樣構造目標函數，才便於用凸優化或其他框架來求解。而這些方面的訓練，要比機器學習的模型還要紮實才行。</p>
<img class="content-image" src="https://pic1.zhimg.com/v2-37dfc082fe36ff76e6afe5b5f67b64b8_b.jpg" alt="">
<p>拿大家以爲"以不變應萬變"的深度學習舉個例子。用神經網絡處理語音識別、自然語言處理這種時間序列數據的建模，RNN（見上圖）是個自然的選擇。不過在實踐中，大家發現由於&ldquo;梯度消失&rdquo;現象的存在，RNN 很難對長程的上下文依賴建模。而在自然語言中，例如決定下面的 be 動詞是&ldquo;is&rdquo;還是&ldquo;are&rdquo;這樣的問題，有可能往前翻好多詞才能找到起決定作用的主語。怎麼辦呢？天才的 J. Schmidhuber 設計了帶有門結構的 LSTM 模型（見下圖），讓數據自行決定哪些信息要保留，那些要忘掉。如此以來，自然語言的建模效果，就大大提高了。大家初看下面兩張 RNN 與 LSTM 的結構對比，面對憑空多出來的幾個門結構可能一頭霧水，唯有洞徹其中的方法論，並且有紮實的機器學習和最優化基礎，才能逐漸理解和學習這種思路。</p>
<img class="content-image" src="https://pic4.zhimg.com/v2-c78d63c52739e465c6f3ac856358e80b_b.jpg" alt="">
<p>當然，LSTM 這個模型是神來之筆，我等對此可望不可及。不過，在這個例子裏展現出來的關鍵能力：根據問題特點調整模型，並解決優化上的障礙，是一名合格的算法工程師應該追求的能力。年薪 50 萬能找到這樣的人，是物有所值的。</p>
<p><strong>第三層次&ldquo;<strong>Objective&rdquo;：</strong>擅定義問題</strong></p>
<p>這個層次的工程師（哦，似乎叫工程師不太合適了），扔給他一個新的實際問題，可以給出量化的目標函數。</p>
<p>當年，福特公司請人檢修電機，斯坦門茨在電機外殼畫了一條線，讓工作人員在此處打開電機迅速排除了故障。結賬時，斯坦門茨要 1 萬美元，還開了個清單：畫一條線，1 美元；知道在哪兒畫線，9999 美元。</p>
<p>同樣的道理，在算法領域，最難的也是知道在哪裏畫線，這就是對一個新問題構建目標函數的過程。<strong>而有明確的量化目標函數，正是科學方法區別於玄學方法、神學方法的重要標誌。</strong></p>
<p>目標函數，有時能用一個解析形式（Analytical form）寫出來，有時則不能。比方說網頁搜索這個問題，有兩種目標函數：一種是 nDCG，這是一個在標註好的數據集上可以明確計算出來的指標；另一種則是人工看 badcase 的比例，顯然這個沒法用公式計算，但是其結果也是定量的，也可以作爲目標函數。</p>
<p>定義目標函數，初聽起來並沒有那麼困難，不就是制定個 KPI 麼？其實不然，要做好這件事，在意識和技術上都有很高的門檻。</p>
<p><strong>一、要建立&ldquo;萬般皆下品、唯有目標高&rdquo;的意識。</strong>一個團隊也好、一個項目也好，只要確立了正確的、可衡量的目標，那麼達到這個目標就只是時間和成本的問題。假設 nDCG 是搜索的正確目標函數，那麼微軟也好、Yahoo!也好，遲早也能追上 Google，遺憾的是，nDCG 這個目標是有點兒問題的，所以後來這兩家被越拉越遠。</p>
<p>所謂&ldquo;本立而道生&rdquo;：<strong>一個項目開始時，總是應該先做兩件事：一是討論定義清楚量化的目標函數；二是搭建一個能夠對目標函數做線上 A/B 測試的實驗框架。</strong>而收集什麼數據、採用什麼模型，倒都在其次了。</p>
<p><strong>二、能夠構造準確(信)、可解(達)、優雅(雅)的目標函數。</strong>目標函數要儘可能反應實際業務目標，同時又有可行的優化方法。一般來說，優化目標與評測目標是有所不同的。比如說在語音識別中，評測目標是&ldquo;詞錯誤率&rdquo;，但這個不可導所以沒法直接優化；因此，我們還要找一個&ldquo;代理目標&rdquo;，比如似然值或者後驗概率，用於求解模型參數。評測目標的定義往往比較直覺，但是要把它轉化成一個高度相關，又便於求解的優化目標，是需要相當的經驗與功力的。在語音建模裏，即便是計算似然值，也需要涉及 Baum-Welch 等比較複雜的算法，要定義清楚不是簡單的事兒。</p>
<p>優雅，是個更高層次的要求；可是在遇到重大問題時，優雅卻往往是不二法門。因爲，往往只有漂亮的框架才更接近問題的本質。關於這點，必須要提一下近年來最讓人醍醐灌頂的大作&mdash;&mdash;生成對抗網絡（GAN）。</p>
<p>GAN 要解決的，是讓機器根據數據學會畫畫、寫文章等創作性問題。機器畫畫的目標函數怎麼定？聽起來是一頭霧水。我們早年做類似的語音合成問題時，也沒什麼好辦法，只能找人一句句聽來打分。令人拍案叫絕的是，Ian GoodFellow 在定義這個問題時，採取了下圖的巧妙框架：</p>
<img class="content-image" src="https://pic3.zhimg.com/v2-a25e966667525808ab4ef6538bc3d56e_b.png" alt="">
<p>既然靠人打分費時費力，又不客觀，那就乾脆讓機器打分把！好在讓機器認一幅特定語義的圖畫，比如說人臉，在深度學習中已經基本解決了。好，假設我們已經有一個能打分的機器<strong><em>D</em></strong>，現在要訓練一個能畫畫的機器<strong><em>G</em></strong>，那就讓<strong><em>G</em></strong>不斷地畫，<strong><em>D</em></strong>不斷地打分，什麼時候<strong><em>G</em></strong>的作品在<strong><em>D</em></strong>那裏得分高了，就算是學成了。同時，<strong><em>D</em></strong>在此過程中也因爲大量接觸仿品而提升了鑑賞能力，可以把<strong><em>G</em></strong>訓練得更好。有了這樣定性的思考還不夠，這樣一個巧妙設計的二人零和博弈過程，還可以表示成下面的數學問題：</p>
<img class="content-image" src="https://pic1.zhimg.com/v2-0ec4acf9c082afd830ef0e2367a68728_b.jpg" alt="">
<p>這樣一個目標，優雅得象個哲學問題，卻又實實在在可以追尋。當我看到這個式子時，頓時覺得教會機器畫畫是個不太遠的時間問題了。如果你也能對這樣的問題描述感到心曠神怡，就能體會爲什麼這纔是最難的一步。</p>
<p><strong>一個團隊的定海神針，就是能把問題轉化成目標函數的那個人&mdash;&mdash;哪怕他連開源工具都不會用。</strong>100 萬找到這樣的人，可真是撿了個大便宜。</p>
<p>在機器學習領域，算法工程師腳下的進階之路是清晰的：當你掌握了工具、會改造模型，進而可以駕馭新問題的建模，就能成長爲最優秀的人才。沿着這條路踏踏實實走下去，100 萬並不是什麼問題。<strong>什麼？您說還有 300 萬的呢？這個不用眼熱，人家只不過把你寫代碼的時間都用來跳槽了而已。</strong></p>
<hr>
<p>歡迎關注微信公衆號：計算廣告（Comp_Ad）</p>



</div>
</div>
</div>


</div>
</div>