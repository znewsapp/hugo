+++
date = "2017-01-19T19:00:00"
title = "當自動駕駛汽車遇到「電車難題」，它會犧牲主人嗎？"
titleimage = "http://pic1.zhimg.com/021f4afd5e8ca5de4d96968eb4195800.jpg"
ga = 011919
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title">自動駕駛汽車在危險情況下可以不計後果地保護自己的主人嗎？</h2>

<div class="answer">



<div class="content">
<p>1. 自動駕駛汽車的倫理難題</p>
<p>短短几年時間，自動駕駛汽車已經走出谷歌的實驗室，並上路行駛了 274 萬公里，而且進入到了諸多汽車製造商（以及蘋果、百度這樣的公司）下一代產品發佈的日程表，美國多個州已經允許自動駕駛汽車上路，英國剛剛通過了相關法律。然而有這樣一個不可迴避倫理問題，自動駕駛需要在一場交通事故引發的困境（如：保護自己還是衝向路人）中作出決策，然而這一問題相當棘手，人類自己尚且無法給出滿意的答案，現在卻需要交由自動駕駛系統來處理這樣的問題。當然，如果自動駕駛汽車能像谷歌的願景所描述的那樣，交通事故的發生率能降低爲 0，我們便不需要應對這一問題。然而，只要自動駕駛能夠極大提高人們的駕駛安全性，即便這一問題相當棘手，依然值得我們積極設法應對。</p>
<p>自動駕駛汽車的研發者和製造者們包括一些哲學家意識到了這一問題，並試着給出了相應的對策，而這些對策提到了大概要採取怎樣的進路，具體的方案尚在制定中。電影以及科幻作品中對人工智能的討論涉及這一主題，即機器人該怎樣做倫理決策，並依照這些決策去行動，行動又會產生怎樣的後果。比如電影《i Robot》裏，機器人按照人類制定的倫理原則去行動，但由於原則本身的缺陷，本用於造福人類的機器人反而差一點毀滅人類社會。但這類討論並沒有面對最直接的現實問題。所以在此要做的就是從實際的問題 -- 自動駕駛汽車，在特定情境下怎樣做出倫理決策 -- 出發，討論其細節，揭示其中的難點，看是否能得到可行的最佳的對策。</p>
<p>2. 理想化狀況下的解決方案</p>
<p>能夠採取的對策總的來說有三種：其一，把做倫理決策的工作牢牢握在人類自己手中，在困境發生時由駕駛者直接來做出決策；其二，將人類的倫理編製成算法，由計算機按倫理算法的要求做出決策；其三，計算機像人類那樣擁有自己的倫理意識，並據此自主做出決策。</p>
<p>算法優勢在於可以在人類反應極限之外做出反應。&ldquo;自動駕駛車輛應可避免大部分&lsquo;選擇困境&rsquo;&mdash;&mdash;他們的汽車比人反應更迅速、剎車更及時、操縱更靈巧。&middot;&middot;&middot;算法程序說不定能讓汽車躲過一劫&rdquo;。比如，兩車即將相撞，駕駛者去決策的話兩車都將不保，而如果交給計算機則有一車可以保存，儘管它要在兩車中作出選擇。算法可能不總是做出令人滿意的選擇，但好過任由兩車相撞。</p>
<p>算法無法令人滿意的地方在於，它是人們預先設定的，儘管經過充分考慮，總會有遇上沒有預先考慮過情況，計算機只是在機械的執行算法，太過沒有彈性。因此理想的解決方案可能是，由一名像人那樣有思考能力和倫理意識的人工智能去做出判斷，這樣既能在人類無法在場時做出倫理選擇，而且又足夠&ldquo;有人性&rdquo;。但就目前人工智能的發展而言，尚不能勝任。（洛伯納人工智能（Loebner AI）競賽向團隊或個人提供了高達 10 萬美元的獎金，只要其創建的計算機能夠與人類進行某些形式的對話而不被人識破真實身份。10 萬美金的 Loebner 競賽獎金仍無人認領）</p>
<p>採用編制倫理算法的對策可能是相對較好而且在技術上可行的選擇。制定算法必然要處理電車難題這樣的倫理困境，單純地從義務論還是用效益主義出發，似乎都得不到令人滿意的答案。比如我不會贊同，自動駕駛汽車能提高社會總體的交通安全水平，但會是特定的人更危險，尤其當那個特定的人就是我自己。對效益主義和義務論進行調和，以便設計出相對令人滿意的算法，但這種調和不總是可行的。考慮下如下算法，在保障每個人基本利益的情況下，追求總體利益最大化，而且總體利益最大化不得使個人的利益減損。這似乎很理想。但電車難題所要展現的恰是面對不能保障每個人基本利益的情況 -- 一些人活下來一些人死去（沒有比活下來更根本的利益了）。如果每輛車的算法都在保護乘客的基本利益即生命安全，可能適得其反，兩敗俱傷，而本來其中一輛車可以安全脫險的。爲此，算法需要在這種情況下做出選擇，以便有人能夠倖存下來。有三種基本方案，1）保存人數最多的那輛車，2）隨機選擇一輛車保存下來，3）根據乘客預先設定的要求選擇一輛車（比如其中一輛車只有一名乘客，他預先設定，如果遇到上述情況他自願放棄倖存下來的機會）。這三個基本方案可以混合在一起使用，如，在其中一輛車乘客較多的情況下選擇較多的那輛保存，在兩車乘客數相等的情況下隨機選擇一輛。如果不想兩敗俱傷的情況發生，必須制定出一種算法以應對這種狀況。</p>
<p>3. 算法的複雜狀況</p>
<p>儘管不能確定出一種完美的算法，採用自動駕駛汽車倫理算法的對策，依然是一種實際可行，而又相對較好的做法。然而這只是在假設的較爲理想的情況下的討論，自動駕駛汽車倫理困境及其對策並不僅是一個思想實驗。算法涉及更多具體的複雜的情況，只有這些複雜的情況被考慮進來，算法才更有實際意義。這些複雜的情況包括但不限於，1）是否在算法中賦予某些車輛（校車，重要人物的車輛）更高的安全級別，2）自動駕駛汽車有駕駛者嗎，有幾位駕駛者，3）動物在算法中被予以怎樣的考慮，4）如果算法不是唯一的，不同算法的自動駕駛汽車同時上路會又有怎樣的後果，等等。</p>
<p>雖然考慮了所能預料到的各種複雜情況，肯定依然會有未考慮到的情況。而且有可能某些未考慮到的複雜情況，導致採用一種被認爲最好的算法做出的選擇實際上並不是最好的選擇。但及時修補，至少好過放棄使用能考慮到的最好的算法。</p>
</div>
</div>




</div>





<div class="question">
<h2 class="question-title"></h2>

<div class="answer">

<div class="content">
<p>更多討論，查看 知乎圓桌 &middot;&nbsp;<a href="https://www.zhihu.com/roundtable/selfdriving?utm_campaign=official_account&amp;utm_source=zhihudaily&amp;utm_medium=link&amp;utm_content=roundtable">人工智能 &middot; 自動駕駛</a><a href="https://www.zhihu.com/roundtable/audit"><br></a></p>
</div>
</div>


</div>


</div>
</div>