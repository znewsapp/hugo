+++
date = "2017-01-11T20:00:00"
title = "在未來隱私都會消失，而我們只是淪爲大數據中的數字嗎？"
titleimage = "http://pic2.zhimg.com/6888ff3bcbf412237a2904709200fe2d.jpg"
ga = 011120
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title">個人隱私會不會隨着互聯網發展而逐漸消失至不見？</h2>

<div class="answer">



<div class="content">
<p>長文預警。這是極重要的問題，也許會在未來幾十年內主導人們生活的方方面面，同時恰好與自己正在做的研究交叉。這裏結合自己體會和 Acquisti，Taylor 和 Wagman 剛剛發表的綜述，嘗試對此問題做一全面分析。掛一漏萬，敬請諒解。結論是不會，但從當下局面，到最終形成有序格局，中間可能爆發大量爭議，耗費高額成本。個人立場，無論是法律還是政策，應以保障個體權益爲絕對重心，個人數據相關權益，如果不是社會公認，或平臺 / 企業明確告知且消費者同意前提下，都應給予個人。涉及環境、性別等議題的公益組織和活動很多，涉及隱私或數據的卻很少，尤其是在中國。同時，在個人能做到的範圍內，每個人都該反思和重視自身隱私的安全。</p>
<p>隱私給人獨處的可能。早孕的女孩害怕嬰幼用品指南寄到家裏，剛剛失業的父親會因瀏覽器彈出的就業培訓廣告不安。僅僅是想象陌生人拿到自己的基因序列就會讓人恐懼，想要再就業的獲釋犯，或許會跪地祈求僱主不要查詢自己的犯罪記錄。爲隱私一詞，法學家爭論了許多年，都寫進來太冗長，只能討論具體項目。對具體信息，也有幾個層面的保護。最重要幾項，一是你是否有權阻止別人接觸這項信息，二是你是否有權要求獲得信息企業爲信息保持匿名，三是你是否有權要求限制企業對信息用途，四是一旦企業侵犯，你預期能獲得的賠償。權利可以擺在你手裏，也可以放在企業手裏。賠償可高可低。中間這條界限劃在哪，是大家討論重點。</p>
<p>隱私問題有許多獨特之處。一是<strong>極其嚴重的信息不對稱</strong>。如果不是熟諳相關學科，個人很難弄清楚自己被採集了什麼信息，這些信息由誰採集，以及這些信息拿來做了什麼。搜索引擎搜完，網站馬上跳出關鍵詞廣告已經不是新鮮事。打車軟件可能會記錄運動軌跡，搜索引擎可能記下你搜索的疾病關鍵詞，社交媒體忠實記錄你過往的歡笑和糗樣。僱主、民營醫院和保險公司都可能對這些信息很感興趣。個人也很難想象數據在企業手裏怎樣使用，比如說，在 2009 年就有美國學者指出可以利用公開信息推斷社保安全號碼（SSN）（Acquisti 和 Gross，2009）。學術界另一精彩案例是用社交網絡內容和好友關係推斷性向（Jernigan 和 Mistree，2009）。數據挖掘科學進展日新月異，7 年過去的業界，對數據利用的程度和方式很可能是普通人完全無法想像的。</p>
<p>隱私問題獨特性第二點在<strong>你幾乎無法追回隱私</strong>。前面提到，我們很難想象企業拿個人信息做了什麼，其中就包括企業究竟把信息賣給了誰。如果你在搜索引擎搜索關鍵詞&ldquo;運動鞋&rdquo;，這一信息可能馬上就匯入洪流，和其它幾百上千人搜索記錄一起，被實時投標拍賣，然後形成廣告，&ldquo;恰好&rdquo;顯示在你正欲觀看的電視劇之前。你可能不喜歡自己信息被這樣利用，希望說，不要再收集了，已經收集的是不是能刪掉（似乎談不上歸還）。可是，這信息在短短時間裏也許幾經易手多次，從引擎到廣告投放平臺，再到另一家廣告投放平臺再到廠商，最後再繞回來。僅僅是弄清楚這條產業鏈就要花很大力氣，遑論追回。這個問題恐怕比在線維權還要困難很多，很可能連求償對象都找不到。也許自己主動公開或被收集的信息現在沒什麼問題，但要準確估計未來影響，難。</p>
<p>隱私問題獨特性第三點在<strong>個人很難在無孔不入的非法侵犯面前保守隱私</strong>。讓我先來講個故事。電子郵件和垃圾郵件誕生日不差多少，可謂兩兄弟。20 世紀末全世界已深受垃圾郵件困擾。當時就有經濟學家建議用如下方式遏制：將電子郵件和個人賬戶綁定，發件人要爲每封郵件向收件人支付一筆小小費用，比如 1 分。普通人成本不大，垃圾郵件發送者大虧。但是，限制這一想法推行的就是網絡安全約束，黑客完全可以侵入個人電腦，然後濫發郵件，坐着賺錢。21 世紀初，又有學者提出可以建立隱私市場，讓個人把數據買賣權攥在自己手裏。想法是好的，但考慮到全世界&ldquo;肉雞&rdquo;的規模，黑客恐怕又要發一筆大財。互聯網上，&ldquo;安全&rdquo;是熱詞，&ldquo;黑產&rdquo;也是。如果很多手機可能會被遠程遙控裝上 app，再刪掉，算日活量，恐怕我們也很難指望上面的隱私得到合理保護。</p>
<p>隱私問題獨特性第四點在<strong>個體這方面嚴重的認知偏差</strong>。經濟學有一分支叫行爲經濟學，其中重要話題包括：爲什麼很多人會注意不到唾手可得而非常有用的信息，爲什麼很多人會偏離看起來不難做到而對自己大有好處的行爲。隱私問題，簡直是行爲經濟學成果展覽館。可能場景包括：在各類社交媒體披露信息時，怕是很少想過以後。註冊各類賬戶時幾乎不看用戶協議，也很少去關注更新。明知 Cookies 會定期抓取用戶數據也不去清理。各種使用相同密碼，彷彿在說歡迎撞庫。有一經典成果叫默認選項偏差：即使是決定社保儲蓄這種重大問題，把默認選項設在&ldquo;是&rdquo;，或者&ldquo;否&rdquo;，或者不設，會有十幾個百分點的選擇差距，就不要說平時在網上遇到林林總總的選項了。</p>
<p>隱私問題獨特性第五點在<strong>個人無處可逃</strong>。即使個人精心打理自己社交平臺，努力捂好自己所有信息，平臺依然可以從朋友、親人處公開信息推斷，比如性向。同時，周圍使用社交軟件或平臺者越多，個人壓力就越大。網絡外部性（所謂護城河的重要支流）真真切切存在。同時，即使你不提供信息，只要和你類似個體提供得足夠多，你的努力是徒勞的。也許一位在 X 辦公樓工作的男士不願暴露家庭住址，也不想讓人知道自己的菜餚口味，防止企業利用自己的家庭地址或飲食口味來價格歧視（比如 Katja，2015，給出了某文具網站按郵編顯示不同價格的例子）。但只要他 / 她的同事，或者他 / 她的鄰居顯示了這些信息，並且他和這些人通過一款或幾款軟件連在了一起，概率的力量還是逃不脫。考慮到許多學習模型的特徵，暴露信息越多，新披露信息帶來影響可能越大。</p>
<p>最後，<strong>隱私很難被恰當定價</strong>。很難定價不代表無法定價，也不代表沒有這方面市場。專門在快遞周圍撿單子的人、大批量收購電話號碼的人、利慾薰心出賣儲戶數據的銀行員工、火車站門口收打過孔車票的人，他們都是隱私市場一員。隱私有價，但難被恰當定價。前面提到過，個人很難知曉自己被收集的信息會被拿來做什麼，以及可以拿來做什麼。也許企業知道自己要用數據來做什麼，以及這部分數據可以提升多少績效。但是，即使企業也不知道這些數據明年會有什麼用途，或者與另一個數據庫拼在一起會擦出什麼火花。以當下條件，恐怕也很難維持一個個體企業自願平等交易數據的市場。因此，儘管定義、保護或規制隱私都不能忽略相關的市場，但單靠市場無法解決這個問題。前面提到的幾點都是考慮這一問題無法忽略的因素，也是塑造生態的力量。</p>
<p>前面的說法可能給人留下印象：大數據不好。意不在此。數據科學進步給社會帶來福利早已遍及社會方方面面。從各類分享經濟，再到全方位細化的社交平臺，許多冗餘資源利用起來，很多曾經無法傳遞的信息快速整合，形成新知識。新的關係，在無比廣闊地域內形成。社會從中享受了甚多福利。但是，前面講的問題確實存在，重要性可能低估，且規制的法律或政策沒有跟上。爲方便個人瞭解和評估自己在其中可能面臨的風險，有必要對這領域做全面整理分析。前面講的所有這些問題也並不意味着題主所說會成爲現實。大的原因主要有兩點。一是企業、平臺和個人都有各自激勵，三方互動，相互掣肘，可能路徑很多。既然有企業旨在收集數據，很快也會有企業專門保護隱私。二是政府會跟上。歐盟最早，20 世紀末已有比較嚴格法律。美國在 21 世紀初也加強了對隱私保護，限制網絡數據收集。我國也剛剛通過了《網絡安全法》。可以預期相關公益組織也會崛起。</p>
<p>經濟學界 50 年前就開始關注隱私問題，重點在企業和個體間權利界限。Acquisti，Taylor 和 Wagman 將這方面研究分三撥整理，條理非常清晰。此處直接沿用，補入部分研究。第一撥主要早在年代和 1980 年代早期，參與者多與芝加哥大學有關聯。法經濟學巨擘 Posner 首先反對規制數據披露和收集可能影響。以企業爲例，他們在意僱員特徵，因爲這會影響企業未來利潤。如果不準企業去了解婚姻狀況，他們就會在另外一些方面動心思，比如說減少招年輕女性比例。因爲結婚生產可能擡高成本。反映在整體，導致兩個問題：一是一部分本來會被錄用的應聘者因此被拒，利益受損。二是加劇統計性歧視。美國法律中有許多&ldquo;不能問&rdquo;，同時也有企業不能單純以種族、性別等指標決定是否錄用的規定。目的之一就是保護基本權利同時，解決可能加重的歧視問題。</p>
<p>第二點對規制的批評來自 Stigler，他在信息經濟學有很大貢獻。他的論點是：即使規制隱私不會帶來種種壞處，它也很可能無效。以成績爲例，假設政府規定企業不能主動去了解應聘者成績，這類政策真的會得到施行麼？成績最好的那部分學生會用各種辦法主動和企業說，比方說，在面試時，不經意地從袖口掉出學校蓋章的成績單。最好的學生已經披露，次好的當然也會這麼幹。否則，用人單位會把他 / 她和剩下所有學生混在一起評估，虧了。這個過程會一直持續下去，到最後，只有成績最低那部分學生會選擇不披露，而企業對此也瞭然於心。政策形同虛設。這結論很有意思的一項推論是：部分商學院爲保護學生利益，直接蓋掉所有學生成績（Gottlieb 和 Smetters，2011）。相比於競相披露情況，這很可能改善了所有學生的福利。</p>
<p>反對者中有著名的 Hirshleifer，他的觀點影響很大。個人角度，對隱私泄漏的擔憂，可能導致他 / 她爲了聲譽不去做對自己，對社會很重要的事。比如說，如果醫院可能自由傳遞病人信息，艾滋病人可能就不會去接受治療，因爲名聲很可能毀掉。無論是個人不接受治療，還是社會對疫情缺乏瞭解，都不是好事。社會角度，爲防護和獲取隱私努力可能純是社會浪費。不妨想象以下場景：廠商競相收集消費者數據投放廣告，消費者下載軟件，清理 cookies，花時間精力避免&ldquo;精準投放&rdquo;。如果廣告爲消費者提供了新信息，有價值，那得失可能相抵。但是，也有一些廣告是利用心理學知識誘導，甚至或明或暗造假（比如部分醫院投放的競價廣告）。它們沒有提供新信息，純粹是把錢從一部分人口袋轉進另一部分口袋，中間各種成本都浪費掉了。稅常有扭曲損失，智商稅也有。爭着收智商稅，以及努力爭取不被收智商稅，一來一往都是效率的消散。</p>
<p>第一代成果對後世影響很大。很多第二代、第三代研究，以及許多現行法律、政策、通俗書，拆到根子上還是基於這些原理。但是，即使只是基本原理組合，或與現實稍加結合，問題也會變得十分複雜。第二代研究和第一代中間隔了十年，主要是多了很多具體議題，同時信息產業本身發展，比如密碼學等也被考慮進來。Varian，後來谷歌的首席經濟學家，在 1997 年就主張要爲更開放自由的數據共享提供方便。消費者可能需要更加個性化的服務，或者被一個小社區接納，他們願意爲此給出一部分個人信息。但是，如果沒有足夠的信息，沒有可靠的傳遞和驗證這些信息的渠道，廠商無法利用這些數據，小社羣也難以審查申請加入者。能不能搞在線信息市場？前面提過不行。安全是一個問題。另一糟糕可能是：如果你周圍的人都出售個人信息，你沒有理由不賣。廠商可以推斷太多你的特徵。與其捏在手裏，不如換一張 100 減 30 優惠券。有時候&ldquo;出售&rdquo;會換個名字，叫&ldquo;同意用戶許可，馬上體驗&rdquo;。再加上技術條件和個人知識限制，這市場怕是建不起來。</p>
<p>有些學者嘗試用科斯定理解決這一問題，認爲只要把產權明確好，隱私問題可以得到有效解決（Noam，1997；Kahn，McAndrews 和 Roberds，2000 等）。這個觀點很簡明，但實踐中用處可能不大。考慮到一開始自己總結的六點特徵，界定乾淨隱私的產權可能是一個漫長過程。有許多傑出法學家和法律實務工作者在努力，但新問題在不斷冒。隱私無形，去處難控，組合效果可能 1 加 1 大於 2，這些都是阻礙因素。另一問題是財富效應。霧霾問題也可以用科斯定理，但是，把排污權利分配給市民，還是工廠，對財富分配影響很大。既然可能存在財富效應，用科斯定理可靠性有疑問。隱私問題同理，利用這麼多信息權利不同，不太可能沒有財富效應。此外，相關問題中有信息不對稱，利益相關方一般至少有三方（個人、平臺、企業），這些都可能導致定理失效。</p>
<p>以上是第二代理論的一些主要成果。第三代理論更復雜，主要有兩特點。首先，模型變得更復雜。帶有三個甚至更多參與者的模型，稍稍一般化的設定，求解就會非常困難。各派間理論非常多。其次，經濟學家開始利用互聯網公司生成的海量數據檢驗理論，估計模型，爲政策制定者或企業提供建議。其中一部分非常複雜，也許其實沒有必要。自己見解，新模型最大進展在兩方面，一是允許更復雜信息結構，比如引入聲譽系統、評價系統，或者考慮企業根據消費者各類信息來價格歧視，二是嚴格處理平臺。以前者爲例，如果企業可以嚴格記錄消費者瀏覽歷史，進而得知消費者對何種產品感興趣，企業就可能提價。如果消費者預期到這一點，他們就會推遲，或者乾脆減少購買來逃避價格歧視。無論是擔心轉賣，還是擔憂價格歧視，都有可能導致消費者延遲提供信息，或故意扭曲信息，或特意匿名，甚至棄絕服務。這方面有許多理論，@司馬懿 <a href="https://zhuanlan.zhihu.com/p/24494792?refer=econ-and-history">知乎專欄</a>&nbsp;對其中兩個例子有精彩介紹。他的評論直指核心：消費者在信息披露中受益或受損取決於消費者和企業相對地位，討價還價能力相對的差距。但是，這個地位的差距，很可能與前期的信息披露有關。</p>
<p>引入平臺後，三方博弈會有許多更精彩結果，但要真正說明現實就是如此，難度更高。這一塊研究在快速發展。核心在於弄清楚搜索引擎或其它平臺的激勵。再次以搜索引擎爲例，它一方面要蒐集信息，改善搜索質量，與其它企業交易，一方面也通過出售競價廣告或修改排名算法等方法直接參與企業與顧客匹配。首先，引擎與顧客利益可能直接衝突。顧客希望引擎不斷改善算法，如實展示結果，不要有廣告。如果搜索引擎真堅持這麼做，顧客可能不願付錢，廠商也不願付錢，無利可圖。因此，引擎要賺錢，要麼得影響用戶使用體驗，引入廣告；要麼直接操縱排名，篡改信息。其次，引擎與廠商利益也可能直接衝突。如果引擎大量把準確信息賣出，廠商以後對自己信息需求可能下降。因此引擎可能限制信息自由流動（Bergemann 和 Bonatti，2015）。</p>
<p>這方面還有很多意想不到的結果。比方說，消費者日益關注隱私安全未必能改善自身處境，反而可能加強壟斷（Campbell，Goldfarb 和 Tucker，2015）。由於選擇太多，同時無法詳細瞭解各廠商保護政策，消費者可能集中選擇知名度較高或信譽較好廠商。對大廠軟件，他們可能一路勾勾勾，不會對具體內容關注太多；對於小廠軟件，他們則會認真審查。這會導致&ldquo;強者愈強&rdquo;。近年來有多篇研究發現，精準投放對廠商而言，效果非常一般（Mayer 和 Mitchell，2012，Blake 等，2015 等）。還是之前那個問題，激勵互動很複雜。消費者可能安全專門的隱私保護軟件，也會有企業專門推出這類產品。他們使用搜索引擎久了以後，第一眼看的可能是頁面中部而非頂部，誰不知道都是推廣呢。如果你的投放太&ldquo;精準&rdquo;，太&ldquo;及時&rdquo;，消費者甚至會心生反感，效果爲負。</p>
<p>林林總總寫了很多，簡單概括成一句話：即使不考慮政府規制，題主所說的世界也不會很快到來。市場各方各有激勵，相互掣肘。他們常常可能藏着信息，甚至特意傳遞錯誤信息。透明的世界，不太可能到來。包括 A/B 實驗在內，這幾年不少研究發現這些新工具未必能帶來想象中的高收益。消費者也會變，變得更聰明，更主動。未來也許會有組織，也許會有訴訟。不清晰的邊界，就像近代海邊落潮露出的肥沃灘塗，常常引發戰爭，不過不是械鬥而已。最後，隱私定義本身也在變。大家不僅爲挖掘出已有數據新用途，還會創造出新的數據指標，不停刷新&ldquo;信息&rdquo;的定義。隱私也需要跟着變。因此，在實現相對平和有序環境之前，漫長的紛爭和纏鬥免不了。對個人，考慮到開頭的六個點，不應該僅僅期待法律和政策跟上漏洞，那也許會滯後很久。也許應該設法對數據產業有基本瞭解，然後看看手機裏各個 app，如支付寶、微信、瀏覽器等，想想可能記錄了哪些信息，哪些後果也許自己承受不了，設法補救。保護隱私的企業、公益組織和律師也可能很快多起來。一些關鍵信息，比如個人基因，應該暫時給予最高的保護。雖然全文很少談及基本權利，但那非常重要。</p>
<p>部分參考文獻：</p>
<p>Acquisti, Alessandro, and Ralph Gross. "Predicting Social Security numbers from public data." <em>Proceedings of the National Academy of Sciences</em> 106.27 (2009): 10975-10980.</p>
<p>Acquisti A, Taylor C R, Wagman L. The Economics of Privacy[J]. Forthcoming, Journal of Economic Literature.</p>
<p>Anderson, Ross, and Tyler Moore. "The economics of information security." <em>Science</em> 314.5799 (2006): 610-613.</p>
<p>Bergemann, Dirk, and Alessandro Bonatti. "Selling cookies." <em>American Economic Journal: Microeconomics</em> 7.3 (2015): 259-294.</p>
<p>Blake, Thomas, Chris Nosko, and Steven Tadelis. "Consumer Heterogeneity and Paid Search Effectiveness: A Large‐Scale Field Experiment." <em>Econometrica</em> 83.1 (2015): 155-174.</p>
<p>Campbell, James, Avi Goldfarb, and Catherine Tucker. "Privacy regulation and market structure." <em>Journal of Economics &amp; Management Strategy</em> 24.1 (2015): 47-73.</p>
<p>Goldfarb, Avi, and Catherine Tucker. "Online display advertising: Targeting and obtrusiveness." <em>Marketing Science</em> 30.3 (2011): 389-404.</p>
<p>Gottlieb, Daniel, and Kent Smetters. <em>Grade non-disclosure</em>. No. w17465. National Bureau of Economic Research, 2011.</p>
<p>Hirshleifer, Jack. "Privacy: Its origin, function, and future." <em>The Journal of Legal Studies</em> 9.4 (1980): 649-664.</p>
<p>Jernigan, Carter, and Behram FT Mistree. "Gaydar: Facebook friendships expose sexual orientation." <em>First Monday</em> 14.10 (2009).</p>
<p>Kahn, Charles M., James McAndrews, and William Roberds. "A theory of transactions privacy." (2000).</p>
<p>Seim, Katja, and Michael Sinkinson. "Mixed pricing in online marketplaces." <em>Quantitative Marketing and Economics</em> (2015): 1-27.</p>
<p>Mayer, Jonathan R., and John C. Mitchell. "Third-party web tracking: Policy and technology." <em>2012 IEEE Symposium on Security and Privacy</em>. IEEE, 2012.</p>
<p>Noam, Eli M. "Privacy and self-regulation: Markets for electronic privacy." <em>Privacy and Self-Regulation in the Information Age</em> (1997): 21-33.</p>
<p>Posner, Richard A. "The economics of privacy." <em>The American Economic Review</em> 71.2 (1981): 405-409.</p>
<p>Resnick, Paul, and Hal R. Varian. "Recommender systems." <em>Communications of the ACM</em> 40.3 (1997): 56-58.</p>
<p>Stigler, George J. "An introduction to privacy in economics and politics." <em>The Journal of Legal Studies</em> 9.4 (1980): 623-644.</p>
</div>
</div>




</div>


</div>
</div>