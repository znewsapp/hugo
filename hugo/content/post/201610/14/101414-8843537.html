+++
date = "2016-10-14T14:00:00"
title = "買個家用機器人端茶倒水，這次也許是近在眼前了"
titleimage = "http://pic4.zhimg.com/8c5ec0565a3e86d596e606e1b2dbde2f.jpg"
ga = 101414
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">



<div class="question">
<h2 class="question-title">最前沿：深度增強學習再發力，家用機器人已近在眼前</h2>
<div class="answer">



<div class="content">
<p><strong>1 前言</strong></p>
<p>如果問你&ldquo;家用機器人真正實用化還需要多久？&rdquo;我說的是那種可以端茶倒水，幫你幹這幹那的機器人，可能你的回答是 10 年，15 年。但是現在，深度增強學習的不斷髮展，很可能將時間縮短到 5 年。</p>
<p>2016 年 9 月 16 號，<strong>Li Feifei&nbsp;</strong>組（瞭解 ImageNet 的知友們肯定都熟悉）放出了最新的 Paper：</p>
<p><a class=" wrap external" href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1609.05143" target="_blank" rel="nofollow noreferrer">Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning </a></p>
<p>做了什麼事呢？使用深度增強學習實現目標驅動的視覺導航。說的簡單一點就是機器人找東西，有一個地面機器人，讓機器人去找一本書，或者去冰箱，機器人就自己去了，然後能找到物體停下。大家先看一下官方的視頻：</p>
<p><img class="content-image" alt=""><span class="z-ico-extern-blue"></span><span class="url"><span class="z-ico-video"></span>http://v.youku.com/v_show/id_XMTczMTM5Mzk4OA==.html</span></p>
<blockquote><strong>實現機器人找東西有多困難呢？</strong><br><br><strong>very hard! 下文我們會說一下傳統機器人學的方法。</strong><br><br><strong>採用深度增強學習實現又有多大的意義？</strong></blockquote>
<p>先說結論。簡單的說就是以前爲了實現機器人找東西這個事情，我們需要做大量的工作，大量的 hand-engineering，但是現在，採用深度增強學習，我們只需要使用神經網絡。就是機器人只根據實時看到的畫面還有目標選擇動作，這和人類的行爲很像。並且整個過程都是學習來的。這種方法具有革命性的意義。</p>
<p>還記得之前那篇文章嗎？<a class="internal" href="https://zhuanlan.zhihu.com/p/21470871?refer=intelligentunit">最前沿：從虛擬到現實，遷移深度增強學習讓機器人革命成爲可能！ - 智能單元 - 知乎專欄</a> 那篇 Paper 作者研究如何通過遷移學習將不同場景學到的知識移植過來。特別是從虛擬到現實的遷移。但是，這篇文章想了個更簡單的做法&mdash;&mdash;我們造一個非常仿真的環境不就完了。</p>
<img class="content-image" src="https://pic4.zhimg.com/v2-92b55a9f3ef3e25426edcba6ab5ef6ff_b.png" alt="">
<p>因此，這篇文章中，作者構建了一個非常好的仿真環境（如上圖），並且通過在高度仿真的環境中訓練，然後遷移到真實場景中。這種方法被證明是有效的。那麼想象一下，如果構建了一個更復雜更真實的場景，然後讓機器人在裏面無限次的訓練學習，掌握技能之後，再移植到現實世界。這將是 game-changing 的事情。讓家用機器人能夠端茶倒水將不再那麼困難。</p>
<p>下面，我們來好好分析一下這篇文章的意義。最重要的是深度增強學習的意義。</p>
<p><strong>2 機器人找東西，傳統的方法怎麼做？</strong></p>
<p>假設我們面前有一臺輪式機器人，有攝像頭，可控制，上面還有一個機械臂。我們希望能夠跟機器人說去幫我拿一個杯子過來。然後機器人能夠自主的去廚房找到一個杯子，用機械臂拿起來，最後送到我手上。那麼爲了實現這麼一個任務，我們首先需要實現的就是去找到杯子這個任務。我們再進一步假設房間裏的東西都是靜止的，然後要求機器人能夠去找房間中的各種物品。</p>
<p>OK，在這種假設下，傳統的機器人學告訴我們要怎麼實現這個系統呢？</p>
<p><strong>Step 1：建圖 Mapping 和定位 Localization 也就是 SLAM</strong></p>
<img class="content-image" src="https://pic1.zhimg.com/v2-05310424cd5a51deeb9a97d6484a8f1c_b.jpeg" alt="">
<img class="content-image" src="https://pic1.zhimg.com/v2-e08704b6dc925b575c2f1fe15e92be84_b.png" alt="">
<p>要想找東西，總得先知道自己在哪，還要知道房間的結構好規劃路線。因此，我們得先利用機器人上面的傳感器比如攝像頭、雷達等構建整個場景，因爲要找東西，有的高，有的低，所以最好還是 3d 場景。</p>
<p><strong>Step 2：構建語義地圖 Semantic Map</strong></p>
<img class="content-image" src="https://pic3.zhimg.com/v2-7b91f9c057908d1b0f311266978921d2_b.jpeg" alt="">
<p>要找東西，當然要知道東西在哪裏了。因此，這一步需要我們在上一步得到的地圖上添加語義，也就是各種東西的位置信息。或者反過來也可以給 3d 地圖裏面的每個東西貼標籤，這是冰箱，我就貼上冰箱的標誌，那是門，那我就貼上門的標籤。大家可以看到，這需要計算機視覺的物體檢測（Object Detection）技術，比如我們可以使用 YOLO 或者 Fast R-CNN 算法在 SLAM 的同時進行物體檢測，爲物體貼上標籤。比如上圖所示，我們知道桌子，椅子，櫃子的具體位置。做完這一步，我們不但知道整個房屋的構造，機器人自己的位置，也知道每一個物體的相對位置。</p>
<p><strong>Step 3：路徑規劃（Path Planning）</strong></p>
<img class="content-image" src="https://pic4.zhimg.com/v2-6d2c266ed5d12dfd50c77b13bce14fb7_b.png" alt="">
<p>有了地圖和定位，再加上目標位置，ok，萬事俱備了。我們只要根據這個設計出一條最佳的路徑，然後讓機器人走就行了。這就是路徑規劃需要乾的事情。</p>
<p><strong>小結一下</strong></p>
<p>在傳統的機器人學中，要實現機器人找東西這件事，需要完成上面三大任務。真是太複雜。單單 SLAM 都是一個很大的研究課題了。而這中間需要的計算量，需要的人力工程，都是非常多的。那麼，這篇 Paper 是怎麼做的呢？</p>
<p><strong>3 深度增強學習是怎麼做的？</strong></p>
<img class="content-image" src="https://pic1.zhimg.com/v2-062f4429783928c286e33d62ddd488d4_b.png" alt="">
<p>深度增強學習的思路就完全不是機器人學的思路了，而是人的思路。上一節我們說又要建圖，又要路徑規劃的。問題是：我們人需要這麼做嗎？不得不承認，我們人具備自動在大腦中構建 3d 場景的能力，但是對於找東西我們並不需要這麼做。我們人就是大致知道東西的位置，然後往那個方向上走就行了。</p>
<p><strong>因此，深度增強學習要僅使用 2D 的視覺信息來完成找東西的任務！</strong></p>
<p>如上圖所示，機器人找東西的任務變成：看到圖像，選擇行走動作，直到找到想要的物體，停下。</p>
<p><strong>這篇文章的創新點在哪呢？</strong></p>
<p>就是將目標圖像作爲輸入！老實說這個創新點非常簡單，也蠻低級的，而且僅針對這種目標能夠具化的任務有效。但是對於機器人找東西而言，等於和人一樣給個目標圖像，然後讓你去找到它。這樣做的好處就是<strong>神經網絡具有通用性。</strong>之前，如果只用當前看到的圖像作爲輸入，那麼每找一個東西，都要單獨訓練一個網絡。現在，把目標圖像作爲輸入進行訓練，那麼就可以使這個網絡不管輸入什麼目標都 ok，也就具備了通用性。</p>
<p>這篇文章採用了&nbsp;<strong><a class=" wrap external" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1602.01783" target="_blank" rel="nofollow noreferrer">A3C 算法</a></strong>，也就是 Deepmind 提出的當前深度增強學習最強的算法來訓練，主要就是神經網絡的模型變了，還有多線程訓練的方式做了一點改變（也就是同時開啓多個 Agent 訓練多個場景多個任務）。甚至，還根據不同場景搞不同的神經網絡來輸出，這算不算通用我得打個問號。</p>
<img class="content-image" src="https://pic4.zhimg.com/v2-dd93e3c95dcb22ec636baf710e73d287_b.png" alt="">
<p>爲了讓觀察的圖像輸入和目標圖像輸入能夠和在一起，爲兩個圖像採用了相同的預訓練好的神經網絡（使用 ImageNet 訓練的深度殘差網絡）。</p>
<p>要理解整個訓練過程，需要熟悉 A3C 算法，鑑於篇幅，這裏就不細講了。本專欄將陸續發佈更多文章介紹深度增強學習的各種算法。</p>
<p>對於這個成果我們應該思考一個問題是：<strong>神經網絡是如何讓機器人找東西的？</strong></p>
<p><strong><strong>4 深度神經網絡通過學習學到了什麼？</strong></strong></p>
<p>它並沒有記住物體的位置，更不知道房屋的結構。但它記住了在每一個位置，通向各個物體的行爲方法。</p>
<p>比如說，冰箱在左前方 5 米，那麼機器人在這個位置的時候根據看到的圖像做出向左前方走的動作。它只是知道要這麼走，它知道這個軌跡，但是並不知道其他。</p>
<p>反過來想，傳統的機器人學方法可以通過記錄軌跡來控制嗎？</p>
<p>當然是可以，但是同樣的，SLAM 和語義地圖還有路徑規劃都是避開不了的工程。而採用深度增強學習，我們是讓機器人通過不斷試錯的方法來找到這條路徑，而不是計算。</p>
<p><strong>5 小結與展望</strong></p>
<p>深度增強學習確實是一種非常模仿人類行爲的思路。在真實環境中，我們確實很難讓機器人通過試錯來找到正確的行爲方式，但是如果我們能夠構建非常逼真的仿真環境的話，我們就很有希望在仿真環境中訓練機器人，然後遷移到真實場景中。這樣的話，讓機器人通過自學習來掌握各種技能就真不是說說而已了。我懷疑 DeepMind 已經在構建非常好的仿真環境訓練他們的機器人，也許 DeepMind 的下一個重量級工作就是深度增強學習的機器人了！</p>
<p><strong>聲明：本文爲原創文章，未經作者允許不得轉載！</strong></p>
<p>本文圖片來源於 Paper 及網絡。</p>



</div>
</div>
</div>


</div>
</div>