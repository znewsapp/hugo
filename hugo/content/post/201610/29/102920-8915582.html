+++
date = "2016-10-29T20:00:00"
title = "計算機視覺進入瓶頸了？還大有搞頭呢"
titleimage = "http://pic1.zhimg.com/2f6af53ac67b2dcf78f125a7d1b3f584.jpg"
ga = 102920
+++

<div class="main-wrap content-wrap">
<div class="headline">

<div class="img-place-holder"></div>



</div>

<div class="content-inner">




<div class="question">
<h2 class="question-title">計算機視覺是否已經進入瓶頸期？</h2>

<div class="answer">



<div class="content">
<p>其實這個問題也是我近段時間一直在思考的問題. 昨天剛在組裏做了個 ECCV'16 Recap, 整理一下思路, 來嘗試拋磚引玉．</p>
<p>我的觀點是：<strong>計算機視覺在人工智能和深度學習的大背景下方興未艾</strong>．</p>
<p>這裏進入瓶頸期的，可能是一些計算機視覺的經典問題，如物體識別和檢測（人臉，行人，物體，場景 etc）．但是如果能死磕這些經典問題，往往能帶來質的突破，比如說對於 ImageNet 物體識別 GoogLeNet 之後，大部分人應該都不會想到還有 ResNet 這種牛逼網絡的出現：）．計算機視覺這個領域本身，我覺得是正在蓬勃發展, 經典問題得到了更好的解決, 新的問題也不斷涌現．</p>
<p>如果把 Deep Learning 進入 CV 的 2012 年作爲新時代的開始，我自己是從舊時代來的人．對於從舊時代過來的人，現在無疑是 CV 以及 AI 最好的時代．我自己當年是看着 Dahua Lin 的 blog，以及 @Filestorm 和 @田淵棟在 SJTU 飲水思源 AI 版的論戰進入 CV 和 AI 研究圈子的（這裏特別感謝三位師兄當年的分享），那時候大家討論的東西都是 graphical model, sparse coding, bag of SIFT, spatial pyramid 啥的，也沒有工作搶着放 arXiv 的傳統，也沒有滿大街的 open source libraries. 每年 CVPR 接收的論文到現在的 1/2 都不到. 每次開會前 proceeding 放出來的時候都會沐浴更衣把大部分感興趣的論文掃一遍.</p>
<p>現在的 CV 和 AI 研究其實是變得越來越扁平快了．隨手可得的 open source libraries 和 pretrained models, 互聯網上各種分享的學習資料和經, 便宜的 GPU 計算資源, 以及百花齊放的研究方向，都使得新入行的生猛年輕人能很快倒騰出新東西. 發表 CVPR， NIPS， AAAI 等頂會文章也不再是難事. 論文數量和研究方向也是繁多. 已經很難 follow.</p>
<p>現在很多時候, 我覺得做 CV 的研究更像是在拼工程能力, 而不是拼 insight 和積累了. 後來的人也許並沒有多少動力和精力去學習和了解之前的經典. 這也是我擔憂的地方. 但時代造人, 這些也是無可厚非的, 畢竟我們希望更多有闖勁的年輕人進入 CV 和 AI 圈子, 一起大鍊鋼:). 爭先放 arXiv, 開源 code 等無疑加速了研究的迭代速度, 有更大的可能性激發出新的研究方向和成果. 大公司們(Google, Facebook, Amazon)以及諸多 startup 們, 也都虎視眈眈地渴望着更多更好的研究工作出現.</p>
<p>另外, 如果硬要我說幾個 CV 目前有肉容易啃的方向, 那我就大致提提（注：這些方向大致都偏純學術，有什麼商業價值我並不是怎麼關心）:</p>
<p><strong>1. Robotics (or Simulation Graphics)+Vision</strong>. Robotics 那邊的人普遍比較保守, 更執着於傳統 template matching 之類的傳統方法. 這裏有個段子, 我們 MIT 機械工程系 robotics 方向的大牛教授 John Leonard 很久以前評論 Computer vision, 直接說你們'CVPR'裏面的各種論文, 就是 Computer Vision and Precision Recall. 什麼意思大家應該能理解:). 不過在 deep learning 開始真正 work 的時代, 他這句話應該不太適用了(笑). 回到正題, Robitics 本身是塊非常大的餅, 很多問題和方法都可以用 deep learning (CNN + Deep Reinforcement learning) 重新解決. 偏 Robotics 的話, 大家可以留意一下 Berkeley 的大紅人 Sergey Levine 最近的工作(<a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>). 偏 Vision 的話，可以看看 CMU 的大紅人 Abinav Gupta 的 ECCV paper Curious Robot (<a href="https://arxiv.org/pdf/1604.01360v2.pdf">https://arxiv.org/pdf/1604.01360v2.pdf</a>). Jianxiong Xiao 之前主打的 3D deep learning (<a href="http://robots.princeton.edu/talks/2016_MIT/RobotPerception.pdf">http://robots.princeton.edu/talks/2016_MIT/RobotPerception.pdf</a>)也可以算在這個裏面，他們團隊和 MIT 團隊最近搞了個 Amazon Pick challenge, 模型和方法還有點意思（<a href="http://www.cs.princeton.edu/~andyz/apc2016">MIT-Princeton Vision Dataset for the APC 2016</a>）. 不過 Xiao 已經下海經商, 不知道還會不會 actively publish. 現在各大公司和 startup 猛搞的 autonomous drive, 也可以放在這個方向之下.</p>
<p>最近我還留意到一個非常有潛力的方向 Simulation+Vision. 我覺得有兩個具體方向，一個是利用 graphics 裏面的 rendering 仿真技術，生成大量數據．這些數據因爲是生成出來的，任何 ground-truth 都有，而且要多少有多少, 是獲取訓練數據的一個捷徑．CVPR'16 有篇做 synthetic image dataset for semantic segmentation of urban scene（<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ros_The_SYNTHIA_Dataset_CVPR_2016_paper.pdf">http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ros_The_SYNTHIA_Dataset_CVPR_2016_paper.pdf</a>）．另外一個方向是結合 graphics 中的 simulation，利用 deep reinforcement learning 等 active learning 的算法可以無監督／弱監督訓練出 agent model，這裏就不僅限於純 CV 了．DeepMind 和 OpenAI 在猛搞這個方向．偏 vision 的話大家可以參考下 Allen Institute 這篇（<a href="https://arxiv.org/pdf/1609.05143v1.pdf">https://arxiv.org/pdf/1609.05143v1.pdf</a>）．</p>
<p><strong>2. Generative visual models.</strong> 目前大部分的模型都是 discrminative model, 給定 input, 然後識別 label. 但這個故事的另外一半其實是 generative model, 給定 label, 然後生成圖片. generative models 是一個很有潛力的大方向. 這裏的最新進展一方面是基於 GAN (<a href="https://arxiv.org/pdf/1511.06434v2.pdf">https://arxiv.org/pdf/1511.06434v2.pdf</a>) 所帶來的一種訓練圖片生成的新思路, 也包括一些基於傳統 image model, 如 MRF 和 CRF 在 deep learning 的新思路下面進行重新理解. DeepMind 的這篇 PixelCNN(<a href="https://arxiv.org/pdf/1606.05328v2.pdf">https://arxiv.org/pdf/1606.05328v2.pdf</a>), 最近 Zhirong 和 Dahua 的挺不錯的 ECCV 論文(<a href="http://dahua.me/papers/dhlin_deepmrf.pdf">http://dahua.me/papers/dhlin_deepmrf.pdf</a>). 個人覺得 Varionational Autoencoder 也是個蠻漂亮的模型, 這裏有篇關於 VAE 的最新的 tutorial 還不錯(<a href="https://arxiv.org/pdf/1606.05908v2.pdf">https://arxiv.org/pdf/1606.05908v2.pdf</a>). 以後 deep learning 跟 bayesian model 的結合也會是個頗具潛力的方向.</p>
<p>3. <strong>Multimedia Computer Vision.</strong> 其實人的感知系統本身就是多模態的, 視頻和聲音共同結合．Video analysis 不再侷限於 action recognition, 對內容本身有更深的理解. 比如說最近的 MoiveQA (<a href="http://movieqa.cs.toronto.edu/home/">MovieQA</a>), Visual Anticipation prediction (<a href="http://web.mit.edu/vondrick/prediction.pdf">http://web.mit.edu/vondrick/prediction.pdf</a></p>
<p>). 另外, sound 也是一個大家普遍忽略掉的一個東西. 大家可以看看我們組 Andrew Owen 的兩個蠻有意思的工作 ECCV'16 Ambient Sound Provides Supervision for Visual Learning (<a href="https://arxiv.org/pdf/1608.07017.pdf">https://arxiv.org/pdf/1608.07017.pdf</a>), CVPR'16 Visually Indicated Sounds (<a href="http://vis.csail.mit.edu/">Visually Indicated Sounds</a>). 多模態來研究 vision 是個大趨勢.</p>
</div>
</div>




</div>


</div>
</div>